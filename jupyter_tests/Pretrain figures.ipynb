{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "oriental-afternoon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mads/miniconda3/envs/NavRepEnv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mads/miniconda3/envs/NavRepEnv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mads/miniconda3/envs/NavRepEnv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mads/miniconda3/envs/NavRepEnv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mads/miniconda3/envs/NavRepEnv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mads/miniconda3/envs/NavRepEnv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ros was not found, disabled.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "from CMap2D import flatten_contours, render_contours_in_lidar, CMap2D, CSimAgent, fast_2f_norm\n",
    "\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines.gail import ExpertDataset\n",
    "\n",
    "from navrep.tools.custom_policy import CustomPolicy, ARCH, _C\n",
    "from navrep.envs.e2eenv import E2ENavRepEnvPretrain\n",
    "from navrep.tools.expert_policy import FastmarchORCAPolicy, alt_generate_expert_traj\n",
    "from crowd_sim.envs.utils.action import ActionXYRot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "decent-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "class E2ENavRepEnvPretrainNoRot(E2ENavRepEnvPretrain):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(E2ENavRepEnvPretrainNoRot, self).__init__(*args, **kwargs)\n",
    "    def reset(self):\n",
    "        self.encoder.reset()\n",
    "        \n",
    "        self.steps_since_reset = 0\n",
    "        self.episode_reward = 0\n",
    "        _, _ = self.soadrl_sim.reset(self.scenario, compute_local_map=False)\n",
    "        random_rot = ActionXYRot(0, 0, 0.*(np.random.random()-0.5))\n",
    "        self.soadrl_sim.step(random_rot, compute_local_map=False, border=self.border)\n",
    "        if not self.LEGACY_MODE:\n",
    "            self._add_border_obstacle()\n",
    "        contours = self.soadrl_sim.obstacle_vertices\n",
    "        self.flat_contours = flatten_contours(contours)\n",
    "        self.distances_travelled_in_base_frame = np.zeros((len(self.soadrl_sim.humans), 3))\n",
    "        obs = self._convert_obs()\n",
    "        if self.LEGACY_MODE:\n",
    "            state, local_map, reward, done, info = self.soadrl_sim.step(\n",
    "                ActionXYRot(0, 0, 0), compute_local_map=True, border=self.border)\n",
    "            obs = (state, local_map)\n",
    "        \n",
    "        h = self.encoder._encode_obs(obs, np.array([0,0,0]))\n",
    "        N = h.shape[0]\n",
    "        h = h.reshape((N,))\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "structural-gibson",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_no_rot = E2ENavRepEnvPretrainNoRot(silent=True, adaptive=False, collect_statistics=False)\n",
    "env_no_rot.soadrl_sim.human_num = 2\n",
    "env_no_rot.soadrl_sim.num_walls = 1\n",
    "env_no_rot.soadrl_sim.num_circles = 0\n",
    "\n",
    "env_rot = E2ENavRepEnvPretrain(silent=True, adaptive=False, collect_statistics=False)\n",
    "env_rot.soadrl_sim.human_num = 2\n",
    "env_rot.soadrl_sim.num_walls = 1\n",
    "env_rot.soadrl_sim.num_circles = 0\n",
    "\n",
    "env_difficult = E2ENavRepEnvPretrain(silent=True, adaptive=True, collect_statistics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "employed-webcam",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4101,)\n",
      "actions (52791, 2)\n",
      "obs (52791, 4101)\n",
      "rewards (52791,)\n",
      "episode_returns (500,)\n",
      "episode_starts (52791,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'actions': array([[-0.42965959, -0.06140743],\n",
       "        [-0.66069858,  0.36724222],\n",
       "        [-0.93753837,  0.25530783],\n",
       "        ...,\n",
       "        [-0.07077036, -0.20369188],\n",
       "        [-0.06519951, -0.18309845],\n",
       "        [-0.06127269, -0.192726  ]]),\n",
       " 'obs': array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ..., -0.42965959,\n",
       "         -0.06140743,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ..., -0.66069858,\n",
       "          0.36724222,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ..., -0.07309605,\n",
       "         -0.20998105,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ..., -0.07077036,\n",
       "         -0.20369188,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ..., -0.06519951,\n",
       "         -0.18309845,  0.        ]]),\n",
       " 'rewards': array([8.29162162e-03, 8.74589958e-03, 1.46165881e-02, ...,\n",
       "        4.31177843e-03, 3.88535975e-03, 1.00000000e+02]),\n",
       " 'episode_returns': array([-2.67885453e+01, -4.25597114e+01,  7.15626328e+01,  8.37233985e+01,\n",
       "         7.70133142e+01,  8.76752236e+01,  7.08527842e+01, -4.60932983e+01,\n",
       "         5.29761527e+01,  6.61986808e+01,  5.47741880e+01,  7.22038279e+01,\n",
       "         6.78929607e+01,  5.84200808e+01,  7.85355700e+01, -2.75864718e+01,\n",
       "         7.86644334e+01,  2.95472018e+01,  7.99906053e+01, -1.14080071e+02,\n",
       "         8.07465675e+01,  7.18622139e+01,  4.82656761e+01,  7.75707633e+01,\n",
       "         8.67416189e+01,  6.86642626e+01,  6.27516711e+01,  8.97552390e+01,\n",
       "         8.35811725e+01,  5.95815102e+01, -1.35693826e+02, -1.17300800e+02,\n",
       "        -4.29573367e+01,  8.05231887e+01,  8.33091404e+01, -4.58060857e+01,\n",
       "        -2.01251412e+02,  6.78968729e+01,  7.53031630e+01,  7.19127038e+01,\n",
       "         7.59677218e+01,  4.04904587e+01,  9.07641233e+01,  6.99404290e+01,\n",
       "         6.93483321e+01, -2.88863123e+01,  5.82861756e+01,  8.60714318e+01,\n",
       "        -3.86450504e+01,  6.54458413e+01,  9.10638073e+01,  9.08097751e+01,\n",
       "         7.22151509e+01,  8.29723925e+01,  1.01763320e+02,  8.93347841e+01,\n",
       "         8.65743786e+01, -5.45346574e+01, -1.12151613e+02, -1.09603807e+02,\n",
       "         6.05733505e+01, -2.62781513e+01, -2.75547646e+01,  9.02127171e+01,\n",
       "         6.17498830e+01,  7.68188410e+01,  5.02538017e+01, -2.62326124e+01,\n",
       "         7.22378949e+01,  7.38815564e+01,  6.70908916e+01,  4.14191537e+01,\n",
       "        -8.41775516e+01,  5.66224341e+01,  5.17107454e+01,  8.97261857e+01,\n",
       "        -1.50566950e+02,  8.48915675e+01, -2.97804031e+01,  7.10952745e+01,\n",
       "         7.39909119e+01, -2.90978123e+01,  7.12897692e+01, -4.50872865e+01,\n",
       "         1.01711418e+02,  7.91472464e+01,  8.67507557e+01,  6.07564952e+01,\n",
       "        -2.64122869e+01,  6.82846157e+01,  4.30519304e+01,  8.98918515e+01,\n",
       "        -3.59190591e+01,  9.42315217e+01,  4.66040716e+01,  5.21215379e+01,\n",
       "         8.68378812e+01,  6.18439058e+01, -8.66166329e+01, -1.37044509e+02,\n",
       "         3.22724180e+01,  1.01279713e+02,  9.05099783e+01,  8.09303249e+01,\n",
       "         8.23031279e+01,  6.17728855e+01,  7.62351922e+01,  5.07495174e+01,\n",
       "         6.94576906e+01,  3.41015218e+01,  7.96137485e+01,  3.44481850e+01,\n",
       "        -3.26126348e+01,  8.73073187e+01,  1.01763927e+02,  8.49428905e+01,\n",
       "         9.24426327e+01,  9.15876734e+01,  9.16733914e+01, -2.53548746e+01,\n",
       "         2.77292007e+01,  3.19728300e+01, -2.98943964e+01,  4.90797596e+01,\n",
       "         8.47487263e+01, -7.03767800e+01,  3.83818767e+01,  7.72711893e+01,\n",
       "         1.28347977e+01, -1.30173165e+02,  9.13935206e+01,  5.98534886e+01,\n",
       "         8.19599260e+01,  8.47933095e+01,  7.76452702e+01, -4.41424330e+01,\n",
       "        -7.61054472e+01,  9.16263926e+01,  9.07690260e+01, -1.33079981e+02,\n",
       "        -4.20572326e+01,  5.43417389e+01,  6.87187201e+01, -2.69106070e+01,\n",
       "        -3.38496420e+01,  6.47538829e+01,  5.81059953e+01, -2.54662933e+01,\n",
       "        -4.26152184e+01, -4.89768426e+01, -3.96129893e+01,  8.02767405e+01,\n",
       "        -3.17566002e+01, -8.38756489e+01, -7.28485437e+01,  6.15737729e+01,\n",
       "         8.34273458e+01, -2.77311872e+01,  5.65765523e+01, -6.45242484e+01,\n",
       "         4.91704397e+01,  7.43603074e+01,  8.28323897e+01,  7.41671510e+01,\n",
       "        -6.92415441e+01, -2.72371745e+01,  9.22871865e+01, -2.76231690e+01,\n",
       "        -1.14154921e+02, -5.72324380e+01,  6.11063131e+01,  8.01484001e+01,\n",
       "         4.31598085e+01, -8.52661414e+01,  8.78570290e+01,  3.95806591e+01,\n",
       "         6.85812112e+01,  6.47617560e+01, -3.91401081e+01,  3.86225003e+01,\n",
       "         8.98681021e+01, -8.75688111e+01,  1.01484943e+02,  8.24434244e+01,\n",
       "         6.99996342e+01,  5.77612412e+01,  8.47594199e+01,  8.46448202e+01,\n",
       "        -3.57071638e+01,  9.09701640e+01,  7.55297796e+01,  5.88167911e+01,\n",
       "         1.01761373e+02, -1.44286425e+02,  7.82444662e+01,  7.76583193e+01,\n",
       "         6.44164701e+01,  7.65910037e+01, -3.92454436e+01,  9.16236707e+01,\n",
       "        -1.61596964e+02, -1.17660845e+02,  5.81521695e+01,  5.57427421e+01,\n",
       "        -6.79913305e+01,  4.66086947e+01,  4.82390953e+01,  8.53398826e+01,\n",
       "         6.65044159e+01, -2.16915355e+01, -1.02466843e+02, -3.45388863e+01,\n",
       "        -5.07409959e+01,  6.47487726e+01,  9.50532493e+01,  6.28496263e+01,\n",
       "        -2.79914135e+01,  5.19097953e+01, -2.69790643e+01,  5.10430965e+01,\n",
       "         7.09558508e+01, -1.40767480e+02, -3.87701921e+00,  8.74184749e+01,\n",
       "         1.00160087e+02,  1.41667460e+01,  9.10542393e+01,  7.47498358e+01,\n",
       "        -1.64647878e+02,  8.86101205e+01,  6.01630946e+01,  2.67449565e+01,\n",
       "         5.50514314e+01,  8.61201289e+01, -3.19584280e+01,  7.47138411e+01,\n",
       "         7.29737041e+01,  7.27516951e+01,  8.38209567e+01,  2.55947602e+01,\n",
       "        -1.02432195e+02,  4.49955888e+01, -7.67760363e+01,  3.31434688e+01,\n",
       "         4.22382406e+01,  6.03652205e+01,  5.65351209e+01, -1.33658721e+02,\n",
       "         4.54508391e+01,  7.81636776e+01, -2.50000000e+01, -1.56673159e+02,\n",
       "         8.07610083e+01,  6.77512688e+01,  6.89706590e+01,  7.42901055e+01,\n",
       "         1.01763184e+02, -7.79629928e+01, -2.67185096e+01,  4.68893747e+01,\n",
       "         6.08160417e+01,  8.72046763e+01, -1.64562362e+02,  8.27579917e+01,\n",
       "         8.66018679e+01,  7.60972945e+01, -3.77673388e+01, -1.29969889e+02,\n",
       "         7.85037455e+01,  9.07605502e+01,  8.17526676e+01,  6.01697954e+01,\n",
       "         9.10870127e+01,  7.51443252e+01,  8.87689543e+01, -7.53218875e+00,\n",
       "         6.97626045e+01,  1.01760414e+02,  5.97875343e+01, -1.65998962e+02,\n",
       "        -1.30525027e+02,  7.50297504e+01, -2.70145789e+01, -1.07994328e+02,\n",
       "        -3.79528413e+01,  6.20145463e+01,  7.06538670e+01,  2.12277787e+01,\n",
       "         7.24148293e+01,  8.67584939e+01, -1.48162990e+02,  5.33234028e+01,\n",
       "        -2.57027816e+01,  8.40351946e+01,  9.41703788e+01, -3.21678393e+01,\n",
       "         8.36201746e+01,  8.81095882e+01,  8.17332239e+01, -1.49986310e+02,\n",
       "        -1.87789656e+02,  7.08272153e+01,  1.01750607e+02, -4.94576975e+01,\n",
       "        -2.84012054e+01,  6.48970162e-01,  6.80474517e+01, -1.05677571e+02,\n",
       "         6.29618483e+01,  3.37739110e+01,  5.58809882e+01,  4.70639331e+01,\n",
       "         5.75571844e+01,  7.52041861e+01,  6.83734294e+01,  6.13462329e+01,\n",
       "         5.53492488e+01,  7.19707642e+01,  2.93375936e+01,  9.06663428e+01,\n",
       "        -3.07990550e+01,  1.01656409e+02,  5.04401241e+01,  6.65182939e+01,\n",
       "        -2.78784401e+01,  3.20981968e+01,  5.11218929e+01, -9.74996279e+01,\n",
       "         8.21895277e+01, -4.09520133e+01,  6.14539342e+01, -4.56525567e+01,\n",
       "        -5.37214594e+01,  6.64433327e+01, -1.01100052e+02, -9.49955173e+01,\n",
       "        -5.92129691e+01,  9.11700331e+01, -1.67395839e+02, -3.36411879e+01,\n",
       "        -3.08594976e+01, -7.22873562e+01,  8.95195064e+01,  7.47576077e+01,\n",
       "         7.73557843e+01,  8.95166155e+01,  6.89473920e+01, -3.38993597e+01,\n",
       "         1.27459862e+01,  9.39415419e+01,  8.24663320e+01,  8.85746546e+01,\n",
       "         6.67748944e+01,  5.97916633e+01,  1.00271429e+02, -1.25146332e+02,\n",
       "         4.16047144e+01,  6.77638105e+01,  6.37413191e+01,  7.82630233e+01,\n",
       "         7.06685993e+01, -1.23759327e+02,  5.73616113e+01,  4.99918735e+01,\n",
       "         9.77130340e+01, -1.48683541e+00,  1.80044301e+01,  8.23986448e+01,\n",
       "         9.18877354e+01,  4.13376674e+01,  7.76725166e+01,  4.67449379e+01,\n",
       "         8.53828575e+01, -8.25047007e+01,  6.17497389e+01,  5.85188913e+01,\n",
       "         7.59211212e+01,  5.05461974e+00,  3.00546599e+01,  4.45090762e+01,\n",
       "         5.46839932e+01,  1.01751522e+02, -3.69254932e+01,  5.09332507e+01,\n",
       "         6.61722791e+01,  7.68900655e+01,  6.37499425e+01,  4.80462867e+01,\n",
       "        -1.49768707e+02,  7.88698678e+01, -2.63863421e+01,  8.36757303e+01,\n",
       "         6.35930021e+01,  8.35977071e+01, -1.60623696e+02,  7.45951392e+01,\n",
       "         9.15315563e+01, -9.30799372e+01,  5.57504933e+01, -4.07541557e+01,\n",
       "        -2.96948278e+01, -1.16319722e+02,  5.26525073e+01, -4.93483497e+01,\n",
       "         2.98327170e+01,  3.87625458e+01,  6.27694530e+01,  8.03929302e+01,\n",
       "         9.16041591e+01,  6.29804275e+01,  9.61531455e+01,  6.44760539e+01,\n",
       "         8.67199765e+01, -7.55788304e+01,  8.46049871e+01,  9.89082262e+01,\n",
       "         6.82344676e+01, -6.13139288e+01, -1.54772804e+02, -1.46178158e+02,\n",
       "         8.09342838e+01,  9.97456691e+01,  6.57827126e+01,  7.05026768e+01,\n",
       "        -5.72579049e+00,  8.90781036e+01,  9.23008072e+01,  7.38581318e+01,\n",
       "         6.73665581e+01,  8.87669083e+01, -2.99910206e+01,  8.97594393e+01,\n",
       "        -7.15488824e+01,  8.14022100e+01, -4.12025734e+01,  8.76035676e+01,\n",
       "         8.54755044e+01,  7.42857205e+01,  5.29270688e+01,  9.45028748e+01,\n",
       "         2.51091889e+01,  7.95275511e+01, -2.89269140e+01,  8.21208932e+01,\n",
       "        -5.23550200e+01, -1.13050286e+02,  7.38749027e+01, -1.17505138e+02,\n",
       "         5.51926814e+01,  5.70672771e+01, -5.34709311e-02,  9.68425720e+01,\n",
       "         8.78872575e+01,  7.76795799e+01,  3.13097866e+01, -4.00925779e+01,\n",
       "        -6.33969229e+01,  4.32763495e+01,  9.01302788e+01,  6.40600844e+01,\n",
       "         6.42134429e+01,  7.03701032e+01,  6.11316222e+01,  6.54706922e+01,\n",
       "         7.25789977e+01,  7.14807348e+01, -3.57518875e+01,  5.77885001e+01,\n",
       "         7.82557323e+01, -1.08618512e+02,  7.07492678e+01,  9.51932480e+01,\n",
       "         9.31628458e+01,  7.50281527e+01,  8.62946988e+01,  8.70720589e+01,\n",
       "        -1.43300537e+02,  7.44662589e+01,  8.27597390e+01,  4.01069540e+01,\n",
       "         8.06513274e+01,  1.01765590e+02, -2.64126974e+01,  4.90604271e+01,\n",
       "         1.01374932e+02,  6.02343608e+01,  5.55569884e+01,  9.64452301e-01,\n",
       "        -9.28052458e+01,  8.50860069e+01,  6.78490571e+01, -4.06347571e+01,\n",
       "         7.53957660e+01,  6.28056245e+01,  6.80635648e+01,  6.37480342e+01,\n",
       "         7.97626970e+01,  6.17210449e+01,  5.13354579e+01,  9.61472294e+01]),\n",
       " 'episode_starts': array([ True, False, False, ..., False, False, False])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alt_generate_expert_traj(env_no_rot,500,policy=FastmarchORCAPolicy(suicide_if_stuck=False), save_path = 'fmORCA_humans_no_rot', render=False)\n",
    "#alt_generate_expert_traj(env_rot,500,policy=FastmarchORCAPolicy(suicide_if_stuck=False), save_path = 'fmORCA_humans_rot', render=False)\n",
    "alt_generate_expert_traj(env_difficult,500,policy=FastmarchORCAPolicy(suicide_if_stuck=False), save_path = 'fmORCA_humans_diff', render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acknowledged-jackson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions (52791, 2)\n",
      "obs (52791, 4101)\n",
      "rewards (52791,)\n",
      "episode_returns (500,)\n",
      "episode_starts (52791,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 44\n",
      "Average returns: 36.716863468878664\n",
      "Std for returns: 69.70170255056497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.ppo2.ppo2.PPO2 at 0x7f96a67ed080>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_no_rot = PPO2(CustomPolicy, env_no_rot, verbose=0)\n",
    "#dataset = ExpertDataset(expert_path='fmORCA_humans_no_rot.npz',traj_limitation=1, batch_size=64)\n",
    "#model_no_rot.pretrain(dataset, n_epochs=500)\n",
    "\n",
    "#model_rot = PPO2(CustomPolicy, env_rot, verbose=0)\n",
    "#dataset = ExpertDataset(expert_path='fmORCA_humans_rot.npz',traj_limitation=1, batch_size=64)\n",
    "#model_rot.pretrain(dataset, n_epochs=500)\n",
    "\n",
    "model_diff = PPO2(CustomPolicy, env_difficult, verbose=0)\n",
    "dataset = ExpertDataset(expert_path='fmORCA_humans_diff.npz',traj_limitation=1, batch_size=64)\n",
    "model_diff.pretrain(dataset, n_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "closed-trust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-26.700445]\n",
      "[-25.159101]\n",
      "[-26.866325]\n",
      "[-25.072529]\n",
      "[-25.075518]\n",
      "[-25.717968]\n",
      "[-25.247717]\n",
      "[-25.166935]\n",
      "[-25.056839]\n",
      "[-25.012012]\n",
      "[-25.814096]\n",
      "[-27.810425]\n",
      "[-25.055595]\n",
      "[-31.854746]\n",
      "[-25.166918]\n",
      "[-32.203747]\n",
      "[-25.157665]\n",
      "[-25.023987]\n",
      "[-25.76916]\n",
      "[-25.050709]\n",
      "[-25.078642]\n",
      "[-25.065264]\n",
      "[-25.035376]\n",
      "[-25.0639]\n",
      "[-30.182325]\n",
      "[-54.22718]\n",
      "[-25.058443]\n"
     ]
    }
   ],
   "source": [
    "model= model_long\n",
    "env = model.get_env()\n",
    "obs = env.reset()\n",
    "reward_sum = 0.0\n",
    "for _ in range(1000):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    reward_sum += reward\n",
    "    env.render(save_to_file=False)\n",
    "    if done:\n",
    "        print(reward_sum)\n",
    "        reward_sum = 0.0\n",
    "        obs = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-questionnaire",
   "metadata": {},
   "source": [
    "## Test very long pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "operating-compact",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4101,)\n",
      "actions (10230, 2)\n",
      "obs (10230, 4101)\n",
      "rewards (10230,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10230,)\n",
      "actions (10230, 2)\n",
      "obs (10230, 4101)\n",
      "rewards (10230,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10230,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 224\n",
      "Average returns: 25.535129780296806\n",
      "Std for returns: 75.17856231228428\n",
      "(4101,)\n",
      "actions (10193, 2)\n",
      "obs (10193, 4101)\n",
      "rewards (10193,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10193,)\n",
      "actions (10193, 2)\n",
      "obs (10193, 4101)\n",
      "rewards (10193,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10193,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 197\n",
      "Average returns: 30.14070158287741\n",
      "Std for returns: 68.3747730980344\n",
      "(4101,)\n",
      "actions (10754, 2)\n",
      "obs (10754, 4101)\n",
      "rewards (10754,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10754,)\n",
      "actions (10754, 2)\n",
      "obs (10754, 4101)\n",
      "rewards (10754,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10754,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 152\n",
      "Average returns: 18.750542893171517\n",
      "Std for returns: 79.62851162147648\n",
      "(4101,)\n",
      "actions (10493, 2)\n",
      "obs (10493, 4101)\n",
      "rewards (10493,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10493,)\n",
      "actions (10493, 2)\n",
      "obs (10493, 4101)\n",
      "rewards (10493,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10493,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 84\n",
      "Average returns: 27.228257231544344\n",
      "Std for returns: 64.73054819734665\n",
      "(4101,)\n",
      "actions (10703, 2)\n",
      "obs (10703, 4101)\n",
      "rewards (10703,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10703,)\n",
      "actions (10703, 2)\n",
      "obs (10703, 4101)\n",
      "rewards (10703,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10703,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 272\n",
      "Average returns: 37.19215279370156\n",
      "Std for returns: 64.92244487982968\n",
      "(4101,)\n",
      "actions (10197, 2)\n",
      "obs (10197, 4101)\n",
      "rewards (10197,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10197,)\n",
      "actions (10197, 2)\n",
      "obs (10197, 4101)\n",
      "rewards (10197,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10197,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 205\n",
      "Average returns: 25.940920394796944\n",
      "Std for returns: 77.30948122437457\n",
      "(4101,)\n",
      "actions (10252, 2)\n",
      "obs (10252, 4101)\n",
      "rewards (10252,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10252,)\n",
      "actions (10252, 2)\n",
      "obs (10252, 4101)\n",
      "rewards (10252,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10252,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 125\n",
      "Average returns: 23.565306823137565\n",
      "Std for returns: 70.13875589473496\n",
      "(4101,)\n",
      "actions (10864, 2)\n",
      "obs (10864, 4101)\n",
      "rewards (10864,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10864,)\n",
      "actions (10864, 2)\n",
      "obs (10864, 4101)\n",
      "rewards (10864,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10864,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 221\n",
      "Average returns: 24.34781550498092\n",
      "Std for returns: 79.13629946033889\n",
      "(4101,)\n",
      "actions (10936, 2)\n",
      "obs (10936, 4101)\n",
      "rewards (10936,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10936,)\n",
      "actions (10936, 2)\n",
      "obs (10936, 4101)\n",
      "rewards (10936,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10936,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 206\n",
      "Average returns: 27.29143127541158\n",
      "Std for returns: 69.37065003101152\n",
      "(4101,)\n",
      "actions (10623, 2)\n",
      "obs (10623, 4101)\n",
      "rewards (10623,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10623,)\n",
      "actions (10623, 2)\n",
      "obs (10623, 4101)\n",
      "rewards (10623,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10623,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 223\n",
      "Average returns: 35.039152679058795\n",
      "Std for returns: 69.29233352092251\n",
      "(4101,)\n",
      "actions (10364, 2)\n",
      "obs (10364, 4101)\n",
      "rewards (10364,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10364,)\n",
      "actions (10364, 2)\n",
      "obs (10364, 4101)\n",
      "rewards (10364,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10364,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 191\n",
      "Average returns: 32.0641062197553\n",
      "Std for returns: 70.35020856807506\n",
      "(4101,)\n",
      "actions (10242, 2)\n",
      "obs (10242, 4101)\n",
      "rewards (10242,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10242,)\n",
      "actions (10242, 2)\n",
      "obs (10242, 4101)\n",
      "rewards (10242,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10242,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 148\n",
      "Average returns: 28.01227105339171\n",
      "Std for returns: 65.82062337802236\n",
      "(4101,)\n",
      "actions (10833, 2)\n",
      "obs (10833, 4101)\n",
      "rewards (10833,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10833,)\n",
      "actions (10833, 2)\n",
      "obs (10833, 4101)\n",
      "rewards (10833,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10833,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 210\n",
      "Average returns: 23.60048841619255\n",
      "Std for returns: 78.24773429288977\n",
      "(4101,)\n",
      "actions (10734, 2)\n",
      "obs (10734, 4101)\n",
      "rewards (10734,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10734,)\n",
      "actions (10734, 2)\n",
      "obs (10734, 4101)\n",
      "rewards (10734,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10734,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 231\n",
      "Average returns: 28.17036888860899\n",
      "Std for returns: 69.73027913375026\n",
      "(4101,)\n",
      "actions (10477, 2)\n",
      "obs (10477, 4101)\n",
      "rewards (10477,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10477,)\n",
      "actions (10477, 2)\n",
      "obs (10477, 4101)\n",
      "rewards (10477,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10477,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 185\n",
      "Average returns: 32.761633198144956\n",
      "Std for returns: 70.60059245977777\n",
      "(4101,)\n",
      "actions (10415, 2)\n",
      "obs (10415, 4101)\n",
      "rewards (10415,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10415,)\n",
      "actions (10415, 2)\n",
      "obs (10415, 4101)\n",
      "rewards (10415,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10415,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 229\n",
      "Average returns: 33.54033229884331\n",
      "Std for returns: 71.30325750556666\n",
      "(4101,)\n",
      "actions (10117, 2)\n",
      "obs (10117, 4101)\n",
      "rewards (10117,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10117,)\n",
      "actions (10117, 2)\n",
      "obs (10117, 4101)\n",
      "rewards (10117,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10117,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 225\n",
      "Average returns: 19.34893844518489\n",
      "Std for returns: 70.30859566652097\n",
      "(4101,)\n",
      "actions (10838, 2)\n",
      "obs (10838, 4101)\n",
      "rewards (10838,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10838,)\n",
      "actions (10838, 2)\n",
      "obs (10838, 4101)\n",
      "rewards (10838,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10838,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 185\n",
      "Average returns: 24.256966336290265\n",
      "Std for returns: 76.82642182257477\n",
      "(4101,)\n",
      "actions (10691, 2)\n",
      "obs (10691, 4101)\n",
      "rewards (10691,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10691,)\n",
      "actions (10691, 2)\n",
      "obs (10691, 4101)\n",
      "rewards (10691,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10691,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 244\n",
      "Average returns: 23.400961216315018\n",
      "Std for returns: 73.02470302686677\n",
      "(4101,)\n",
      "actions (10707, 2)\n",
      "obs (10707, 4101)\n",
      "rewards (10707,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10707,)\n",
      "actions (10707, 2)\n",
      "obs (10707, 4101)\n",
      "rewards (10707,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10707,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 265\n",
      "Average returns: 41.16677105836175\n",
      "Std for returns: 65.83313266866479\n",
      "(4101,)\n",
      "actions (10123, 2)\n",
      "obs (10123, 4101)\n",
      "rewards (10123,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10123,)\n",
      "actions (10123, 2)\n",
      "obs (10123, 4101)\n",
      "rewards (10123,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10123,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 220\n",
      "Average returns: 36.19286088275124\n",
      "Std for returns: 69.069894900672\n",
      "(4101,)\n",
      "actions (9961, 2)\n",
      "obs (9961, 4101)\n",
      "rewards (9961,)\n",
      "episode_returns (100,)\n",
      "episode_starts (9961,)\n",
      "actions (9961, 2)\n",
      "obs (9961, 4101)\n",
      "rewards (9961,)\n",
      "episode_returns (100,)\n",
      "episode_starts (9961,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 63\n",
      "Average returns: 25.833076610095016\n",
      "Std for returns: 60.818972255493144\n",
      "(4101,)\n",
      "actions (10772, 2)\n",
      "obs (10772, 4101)\n",
      "rewards (10772,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10772,)\n",
      "actions (10772, 2)\n",
      "obs (10772, 4101)\n",
      "rewards (10772,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10772,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 261\n",
      "Average returns: 27.112447744835798\n",
      "Std for returns: 73.58402176726293\n",
      "(4101,)\n",
      "actions (10796, 2)\n",
      "obs (10796, 4101)\n",
      "rewards (10796,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10796,)\n",
      "actions (10796, 2)\n",
      "obs (10796, 4101)\n",
      "rewards (10796,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10796,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 228\n",
      "Average returns: 25.74747800319801\n",
      "Std for returns: 70.50940308952143\n",
      "(4101,)\n",
      "actions (10709, 2)\n",
      "obs (10709, 4101)\n",
      "rewards (10709,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10709,)\n",
      "actions (10709, 2)\n",
      "obs (10709, 4101)\n",
      "rewards (10709,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10709,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 260\n",
      "Average returns: 38.074235409958774\n",
      "Std for returns: 63.191315090077325\n",
      "(4101,)\n",
      "actions (10175, 2)\n",
      "obs (10175, 4101)\n",
      "rewards (10175,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10175,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions (10175, 2)\n",
      "obs (10175, 4101)\n",
      "rewards (10175,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10175,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 216\n",
      "Average returns: 30.736888013938753\n",
      "Std for returns: 73.13734577884635\n",
      "(4101,)\n",
      "actions (10330, 2)\n",
      "obs (10330, 4101)\n",
      "rewards (10330,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10330,)\n",
      "actions (10330, 2)\n",
      "obs (10330, 4101)\n",
      "rewards (10330,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10330,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 224\n",
      "Average returns: 25.976801296230768\n",
      "Std for returns: 65.73547628022942\n",
      "(4101,)\n",
      "actions (10642, 2)\n",
      "obs (10642, 4101)\n",
      "rewards (10642,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10642,)\n",
      "actions (10642, 2)\n",
      "obs (10642, 4101)\n",
      "rewards (10642,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10642,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 289\n",
      "Average returns: 23.061634358964707\n",
      "Std for returns: 78.02797355593637\n",
      "(4101,)\n",
      "actions (11034, 2)\n",
      "obs (11034, 4101)\n",
      "rewards (11034,)\n",
      "episode_returns (100,)\n",
      "episode_starts (11034,)\n",
      "actions (11034, 2)\n",
      "obs (11034, 4101)\n",
      "rewards (11034,)\n",
      "episode_returns (100,)\n",
      "episode_starts (11034,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 196\n",
      "Average returns: 23.844777681899927\n",
      "Std for returns: 75.70598644169026\n",
      "(4101,)\n",
      "actions (10717, 2)\n",
      "obs (10717, 4101)\n",
      "rewards (10717,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10717,)\n",
      "actions (10717, 2)\n",
      "obs (10717, 4101)\n",
      "rewards (10717,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10717,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 139\n",
      "Average returns: 42.195810864739705\n",
      "Std for returns: 61.69579768352215\n",
      "(4101,)\n",
      "actions (10302, 2)\n",
      "obs (10302, 4101)\n",
      "rewards (10302,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10302,)\n",
      "actions (10302, 2)\n",
      "obs (10302, 4101)\n",
      "rewards (10302,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10302,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 350\n",
      "Average returns: 29.416153751976648\n",
      "Std for returns: 70.60874365678775\n",
      "(4101,)\n",
      "actions (10176, 2)\n",
      "obs (10176, 4101)\n",
      "rewards (10176,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10176,)\n",
      "actions (10176, 2)\n",
      "obs (10176, 4101)\n",
      "rewards (10176,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10176,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 228\n",
      "Average returns: 29.20878491246721\n",
      "Std for returns: 64.88735114765858\n",
      "(4101,)\n",
      "actions (10702, 2)\n",
      "obs (10702, 4101)\n",
      "rewards (10702,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10702,)\n",
      "actions (10702, 2)\n",
      "obs (10702, 4101)\n",
      "rewards (10702,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10702,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 226\n",
      "Average returns: 24.778430865027495\n",
      "Std for returns: 75.75175912836949\n",
      "(4101,)\n",
      "actions (10765, 2)\n",
      "obs (10765, 4101)\n",
      "rewards (10765,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10765,)\n",
      "actions (10765, 2)\n",
      "obs (10765, 4101)\n",
      "rewards (10765,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10765,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 214\n",
      "Average returns: 22.28463697016511\n",
      "Std for returns: 76.76597023647882\n",
      "(4101,)\n",
      "actions (10533, 2)\n",
      "obs (10533, 4101)\n",
      "rewards (10533,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10533,)\n",
      "actions (10533, 2)\n",
      "obs (10533, 4101)\n",
      "rewards (10533,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10533,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 124\n",
      "Average returns: 36.826602943277635\n",
      "Std for returns: 68.32348549333307\n",
      "(4101,)\n",
      "actions (9566, 2)\n",
      "obs (9566, 4101)\n",
      "rewards (9566,)\n",
      "episode_returns (100,)\n",
      "episode_starts (9566,)\n",
      "actions (9566, 2)\n",
      "obs (9566, 4101)\n",
      "rewards (9566,)\n",
      "episode_returns (100,)\n",
      "episode_starts (9566,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 268\n",
      "Average returns: 30.680496884847948\n",
      "Std for returns: 67.53217819733234\n",
      "(4101,)\n",
      "actions (10265, 2)\n",
      "obs (10265, 4101)\n",
      "rewards (10265,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10265,)\n",
      "actions (10265, 2)\n",
      "obs (10265, 4101)\n",
      "rewards (10265,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10265,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 225\n",
      "Average returns: 27.991168550069883\n",
      "Std for returns: 66.73518787434583\n",
      "(4101,)\n",
      "actions (10863, 2)\n",
      "obs (10863, 4101)\n",
      "rewards (10863,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10863,)\n",
      "actions (10863, 2)\n",
      "obs (10863, 4101)\n",
      "rewards (10863,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10863,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 221\n",
      "Average returns: 19.849320868801755\n",
      "Std for returns: 78.29641796099823\n",
      "(4101,)\n",
      "actions (10745, 2)\n",
      "obs (10745, 4101)\n",
      "rewards (10745,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10745,)\n",
      "actions (10745, 2)\n",
      "obs (10745, 4101)\n",
      "rewards (10745,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10745,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 217\n",
      "Average returns: 31.31666516926498\n",
      "Std for returns: 72.30743821908275\n",
      "(4101,)\n",
      "actions (10717, 2)\n",
      "obs (10717, 4101)\n",
      "rewards (10717,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10717,)\n",
      "actions (10717, 2)\n",
      "obs (10717, 4101)\n",
      "rewards (10717,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10717,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 162\n",
      "Average returns: 31.675684980643624\n",
      "Std for returns: 73.31774865470085\n",
      "(4101,)\n",
      "actions (10218, 2)\n",
      "obs (10218, 4101)\n",
      "rewards (10218,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10218,)\n",
      "actions (10218, 2)\n",
      "obs (10218, 4101)\n",
      "rewards (10218,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10218,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 208\n",
      "Average returns: 34.69689601831094\n",
      "Std for returns: 66.97424663261458\n",
      "(4101,)\n",
      "actions (10058, 2)\n",
      "obs (10058, 4101)\n",
      "rewards (10058,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10058,)\n",
      "actions (10058, 2)\n",
      "obs (10058, 4101)\n",
      "rewards (10058,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10058,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 258\n",
      "Average returns: 26.159453543975474\n",
      "Std for returns: 64.45817767784463\n",
      "(4101,)\n",
      "actions (10941, 2)\n",
      "obs (10941, 4101)\n",
      "rewards (10941,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10941,)\n",
      "actions (10941, 2)\n",
      "obs (10941, 4101)\n",
      "rewards (10941,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10941,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 235\n",
      "Average returns: 22.80418586136068\n",
      "Std for returns: 76.22895427901368\n",
      "(4101,)\n",
      "actions (10821, 2)\n",
      "obs (10821, 4101)\n",
      "rewards (10821,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10821,)\n",
      "actions (10821, 2)\n",
      "obs (10821, 4101)\n",
      "rewards (10821,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10821,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 238\n",
      "Average returns: 30.86866865694183\n",
      "Std for returns: 72.91819962730771\n",
      "(4101,)\n",
      "actions (10842, 2)\n",
      "obs (10842, 4101)\n",
      "rewards (10842,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10842,)\n",
      "actions (10842, 2)\n",
      "obs (10842, 4101)\n",
      "rewards (10842,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10842,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 222\n",
      "Average returns: 37.7984733005931\n",
      "Std for returns: 65.61451836297783\n",
      "(4101,)\n",
      "actions (10012, 2)\n",
      "obs (10012, 4101)\n",
      "rewards (10012,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10012,)\n",
      "actions (10012, 2)\n",
      "obs (10012, 4101)\n",
      "rewards (10012,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10012,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 135\n",
      "Average returns: 32.9470375893112\n",
      "Std for returns: 66.03208218024125\n",
      "(4101,)\n",
      "actions (9855, 2)\n",
      "obs (9855, 4101)\n",
      "rewards (9855,)\n",
      "episode_returns (100,)\n",
      "episode_starts (9855,)\n",
      "actions (9855, 2)\n",
      "obs (9855, 4101)\n",
      "rewards (9855,)\n",
      "episode_returns (100,)\n",
      "episode_starts (9855,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 185\n",
      "Average returns: 23.59414433230997\n",
      "Std for returns: 66.86337091506086\n",
      "(4101,)\n",
      "actions (11034, 2)\n",
      "obs (11034, 4101)\n",
      "rewards (11034,)\n",
      "episode_returns (100,)\n",
      "episode_starts (11034,)\n",
      "actions (11034, 2)\n",
      "obs (11034, 4101)\n",
      "rewards (11034,)\n",
      "episode_returns (100,)\n",
      "episode_starts (11034,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 348\n",
      "Average returns: 24.23462124281049\n",
      "Std for returns: 78.86216313810816\n",
      "(4101,)\n",
      "actions (10825, 2)\n",
      "obs (10825, 4101)\n",
      "rewards (10825,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10825,)\n",
      "actions (10825, 2)\n",
      "obs (10825, 4101)\n",
      "rewards (10825,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10825,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 281\n",
      "Average returns: 30.592140836672865\n",
      "Std for returns: 73.02197807559584\n",
      "(4101,)\n",
      "actions (10555, 2)\n",
      "obs (10555, 4101)\n",
      "rewards (10555,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10555,)\n",
      "actions (10555, 2)\n",
      "obs (10555, 4101)\n",
      "rewards (10555,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10555,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 266\n",
      "Average returns: 36.5838961008639\n",
      "Std for returns: 67.4073517887822\n",
      "(4101,)\n",
      "actions (10005, 2)\n",
      "obs (10005, 4101)\n",
      "rewards (10005,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10005,)\n",
      "actions (10005, 2)\n",
      "obs (10005, 4101)\n",
      "rewards (10005,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10005,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trajectories: 1\n",
      "Total transitions: 127\n",
      "Average returns: 28.400553785014136\n",
      "Std for returns: 67.52739943819039\n",
      "(4101,)\n",
      "actions (10378, 2)\n",
      "obs (10378, 4101)\n",
      "rewards (10378,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10378,)\n",
      "actions (10378, 2)\n",
      "obs (10378, 4101)\n",
      "rewards (10378,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10378,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 132\n",
      "Average returns: 25.137817944204777\n",
      "Std for returns: 69.11800775682174\n",
      "(4101,)\n",
      "actions (11092, 2)\n",
      "obs (11092, 4101)\n",
      "rewards (11092,)\n",
      "episode_returns (100,)\n",
      "episode_starts (11092,)\n",
      "actions (11092, 2)\n",
      "obs (11092, 4101)\n",
      "rewards (11092,)\n",
      "episode_returns (100,)\n",
      "episode_starts (11092,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 239\n",
      "Average returns: 27.532997147579266\n",
      "Std for returns: 77.83467116933484\n",
      "(4101,)\n",
      "actions (10803, 2)\n",
      "obs (10803, 4101)\n",
      "rewards (10803,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10803,)\n",
      "actions (10803, 2)\n",
      "obs (10803, 4101)\n",
      "rewards (10803,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10803,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 220\n",
      "Average returns: 26.066201563618524\n",
      "Std for returns: 75.43138185060727\n",
      "(4101,)\n",
      "actions (10296, 2)\n",
      "obs (10296, 4101)\n",
      "rewards (10296,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10296,)\n",
      "actions (10296, 2)\n",
      "obs (10296, 4101)\n",
      "rewards (10296,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10296,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 178\n",
      "Average returns: 37.69053712958703\n",
      "Std for returns: 66.80598731686462\n",
      "(4101,)\n",
      "actions (10135, 2)\n",
      "obs (10135, 4101)\n",
      "rewards (10135,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10135,)\n",
      "actions (10135, 2)\n",
      "obs (10135, 4101)\n",
      "rewards (10135,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10135,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 181\n",
      "Average returns: 26.806396040831128\n",
      "Std for returns: 66.7357932555783\n",
      "(4101,)\n",
      "actions (10519, 2)\n",
      "obs (10519, 4101)\n",
      "rewards (10519,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10519,)\n",
      "actions (10519, 2)\n",
      "obs (10519, 4101)\n",
      "rewards (10519,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10519,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 142\n",
      "Average returns: 28.86291379389656\n",
      "Std for returns: 67.30824189003131\n",
      "(4101,)\n",
      "actions (10801, 2)\n",
      "obs (10801, 4101)\n",
      "rewards (10801,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10801,)\n",
      "actions (10801, 2)\n",
      "obs (10801, 4101)\n",
      "rewards (10801,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10801,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 176\n",
      "Average returns: 20.523075904424704\n",
      "Std for returns: 79.64314256588392\n",
      "(4101,)\n",
      "actions (10838, 2)\n",
      "obs (10838, 4101)\n",
      "rewards (10838,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10838,)\n",
      "actions (10838, 2)\n",
      "obs (10838, 4101)\n",
      "rewards (10838,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10838,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 179\n",
      "Average returns: 25.22774130514105\n",
      "Std for returns: 76.43461003398039\n",
      "(4101,)\n",
      "actions (10242, 2)\n",
      "obs (10242, 4101)\n",
      "rewards (10242,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10242,)\n",
      "actions (10242, 2)\n",
      "obs (10242, 4101)\n",
      "rewards (10242,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10242,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 199\n",
      "Average returns: 38.73625275823697\n",
      "Std for returns: 67.56859242125293\n",
      "(4101,)\n",
      "actions (10084, 2)\n",
      "obs (10084, 4101)\n",
      "rewards (10084,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10084,)\n",
      "actions (10084, 2)\n",
      "obs (10084, 4101)\n",
      "rewards (10084,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10084,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 139\n",
      "Average returns: 26.487263524960618\n",
      "Std for returns: 67.87787180514454\n",
      "(4101,)\n",
      "actions (10787, 2)\n",
      "obs (10787, 4101)\n",
      "rewards (10787,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10787,)\n",
      "actions (10787, 2)\n",
      "obs (10787, 4101)\n",
      "rewards (10787,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10787,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 226\n",
      "Average returns: 30.608904965868646\n",
      "Std for returns: 69.68337917251732\n",
      "(4101,)\n",
      "actions (10632, 2)\n",
      "obs (10632, 4101)\n",
      "rewards (10632,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10632,)\n",
      "actions (10632, 2)\n",
      "obs (10632, 4101)\n",
      "rewards (10632,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10632,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 308\n",
      "Average returns: 17.2111846992148\n",
      "Std for returns: 82.28851196418431\n",
      "(4101,)\n",
      "actions (10818, 2)\n",
      "obs (10818, 4101)\n",
      "rewards (10818,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10818,)\n",
      "actions (10818, 2)\n",
      "obs (10818, 4101)\n",
      "rewards (10818,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10818,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 229\n",
      "Average returns: 29.109876501984363\n",
      "Std for returns: 71.98839667211074\n",
      "(4101,)\n",
      "actions (10724, 2)\n",
      "obs (10724, 4101)\n",
      "rewards (10724,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10724,)\n",
      "actions (10724, 2)\n",
      "obs (10724, 4101)\n",
      "rewards (10724,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10724,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 209\n",
      "Average returns: 37.345648301706454\n",
      "Std for returns: 70.14520048005984\n",
      "(4101,)\n",
      "actions (10234, 2)\n",
      "obs (10234, 4101)\n",
      "rewards (10234,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10234,)\n",
      "actions (10234, 2)\n",
      "obs (10234, 4101)\n",
      "rewards (10234,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10234,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 148\n",
      "Average returns: 26.866478256443997\n",
      "Std for returns: 68.7763918420613\n",
      "(4101,)\n",
      "actions (11056, 2)\n",
      "obs (11056, 4101)\n",
      "rewards (11056,)\n",
      "episode_returns (100,)\n",
      "episode_starts (11056,)\n",
      "actions (11056, 2)\n",
      "obs (11056, 4101)\n",
      "rewards (11056,)\n",
      "episode_returns (100,)\n",
      "episode_starts (11056,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 151\n",
      "Average returns: 31.47064363653175\n",
      "Std for returns: 71.3050694598552\n",
      "(4101,)\n",
      "actions (10398, 2)\n",
      "obs (10398, 4101)\n",
      "rewards (10398,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10398,)\n",
      "actions (10398, 2)\n",
      "obs (10398, 4101)\n",
      "rewards (10398,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10398,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 247\n",
      "Average returns: 20.91357424178741\n",
      "Std for returns: 74.11132220051799\n",
      "(4101,)\n",
      "actions (10730, 2)\n",
      "obs (10730, 4101)\n",
      "rewards (10730,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10730,)\n",
      "actions (10730, 2)\n",
      "obs (10730, 4101)\n",
      "rewards (10730,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10730,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 176\n",
      "Average returns: 31.850484923338513\n",
      "Std for returns: 69.6169951716091\n",
      "(4101,)\n",
      "actions (10308, 2)\n",
      "obs (10308, 4101)\n",
      "rewards (10308,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10308,)\n",
      "actions (10308, 2)\n",
      "obs (10308, 4101)\n",
      "rewards (10308,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10308,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 302\n",
      "Average returns: 34.261252118477536\n",
      "Std for returns: 71.88495719747893\n",
      "(4101,)\n",
      "actions (10035, 2)\n",
      "obs (10035, 4101)\n",
      "rewards (10035,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10035,)\n",
      "actions (10035, 2)\n",
      "obs (10035, 4101)\n",
      "rewards (10035,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10035,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 219\n",
      "Average returns: 30.944774068377928\n",
      "Std for returns: 62.16296060948607\n",
      "(4101,)\n",
      "actions (10855, 2)\n",
      "obs (10855, 4101)\n",
      "rewards (10855,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10855,)\n",
      "actions (10855, 2)\n",
      "obs (10855, 4101)\n",
      "rewards (10855,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10855,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 183\n",
      "Average returns: 30.342479404080272\n",
      "Std for returns: 71.12675696135368\n",
      "(4101,)\n",
      "actions (10699, 2)\n",
      "obs (10699, 4101)\n",
      "rewards (10699,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10699,)\n",
      "actions (10699, 2)\n",
      "obs (10699, 4101)\n",
      "rewards (10699,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10699,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 187\n",
      "Average returns: 20.983991594893965\n",
      "Std for returns: 74.87630086306656\n",
      "(4101,)\n",
      "actions (10807, 2)\n",
      "obs (10807, 4101)\n",
      "rewards (10807,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10807,)\n",
      "actions (10807, 2)\n",
      "obs (10807, 4101)\n",
      "rewards (10807,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10807,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 237\n",
      "Average returns: 29.604231448501586\n",
      "Std for returns: 71.85073051347813\n",
      "(4101,)\n",
      "actions (10359, 2)\n",
      "obs (10359, 4101)\n",
      "rewards (10359,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10359,)\n",
      "actions (10359, 2)\n",
      "obs (10359, 4101)\n",
      "rewards (10359,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10359,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 166\n",
      "Average returns: 31.872011184239735\n",
      "Std for returns: 72.39133531541293\n",
      "(4101,)\n",
      "actions (10082, 2)\n",
      "obs (10082, 4101)\n",
      "rewards (10082,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10082,)\n",
      "actions (10082, 2)\n",
      "obs (10082, 4101)\n",
      "rewards (10082,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10082,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 248\n",
      "Average returns: 23.139065472938878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std for returns: 69.98797922263044\n",
      "(4101,)\n",
      "actions (10474, 2)\n",
      "obs (10474, 4101)\n",
      "rewards (10474,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10474,)\n",
      "actions (10474, 2)\n",
      "obs (10474, 4101)\n",
      "rewards (10474,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10474,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 260\n",
      "Average returns: 30.077371436174857\n",
      "Std for returns: 69.66888125372562\n",
      "(4101,)\n",
      "actions (10697, 2)\n",
      "obs (10697, 4101)\n",
      "rewards (10697,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10697,)\n",
      "actions (10697, 2)\n",
      "obs (10697, 4101)\n",
      "rewards (10697,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10697,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 202\n",
      "Average returns: 23.952077671067755\n",
      "Std for returns: 74.07223580020381\n",
      "(4101,)\n",
      "actions (10845, 2)\n",
      "obs (10845, 4101)\n",
      "rewards (10845,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10845,)\n",
      "actions (10845, 2)\n",
      "obs (10845, 4101)\n",
      "rewards (10845,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10845,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 226\n",
      "Average returns: 29.91860540750038\n",
      "Std for returns: 71.35371121797554\n",
      "(4101,)\n",
      "actions (10093, 2)\n",
      "obs (10093, 4101)\n",
      "rewards (10093,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10093,)\n",
      "actions (10093, 2)\n",
      "obs (10093, 4101)\n",
      "rewards (10093,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10093,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 207\n",
      "Average returns: 31.785763170826808\n",
      "Std for returns: 67.13710681843415\n",
      "(4101,)\n",
      "actions (10442, 2)\n",
      "obs (10442, 4101)\n",
      "rewards (10442,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10442,)\n",
      "actions (10442, 2)\n",
      "obs (10442, 4101)\n",
      "rewards (10442,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10442,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 179\n",
      "Average returns: 29.08776480797073\n",
      "Std for returns: 65.745843332648\n",
      "(4101,)\n",
      "actions (11180, 2)\n",
      "obs (11180, 4101)\n",
      "rewards (11180,)\n",
      "episode_returns (100,)\n",
      "episode_starts (11180,)\n",
      "actions (11180, 2)\n",
      "obs (11180, 4101)\n",
      "rewards (11180,)\n",
      "episode_returns (100,)\n",
      "episode_starts (11180,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 269\n",
      "Average returns: 31.001703698080792\n",
      "Std for returns: 74.04881053457204\n",
      "(4101,)\n",
      "actions (10640, 2)\n",
      "obs (10640, 4101)\n",
      "rewards (10640,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10640,)\n",
      "actions (10640, 2)\n",
      "obs (10640, 4101)\n",
      "rewards (10640,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10640,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 306\n",
      "Average returns: 28.90360571006347\n",
      "Std for returns: 69.86089503588609\n",
      "(4101,)\n",
      "actions (10889, 2)\n",
      "obs (10889, 4101)\n",
      "rewards (10889,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10889,)\n",
      "actions (10889, 2)\n",
      "obs (10889, 4101)\n",
      "rewards (10889,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10889,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 186\n",
      "Average returns: 32.43831866721674\n",
      "Std for returns: 71.96409552739117\n",
      "(4101,)\n",
      "actions (10600, 2)\n",
      "obs (10600, 4101)\n",
      "rewards (10600,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10600,)\n",
      "actions (10600, 2)\n",
      "obs (10600, 4101)\n",
      "rewards (10600,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10600,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 190\n",
      "Average returns: 27.244450881643534\n",
      "Std for returns: 76.01159591241942\n",
      "(4101,)\n",
      "actions (10418, 2)\n",
      "obs (10418, 4101)\n",
      "rewards (10418,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10418,)\n",
      "actions (10418, 2)\n",
      "obs (10418, 4101)\n",
      "rewards (10418,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10418,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 175\n",
      "Average returns: 30.68797138770909\n",
      "Std for returns: 65.76287573094721\n",
      "(4101,)\n",
      "actions (10643, 2)\n",
      "obs (10643, 4101)\n",
      "rewards (10643,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10643,)\n",
      "actions (10643, 2)\n",
      "obs (10643, 4101)\n",
      "rewards (10643,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10643,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 181\n",
      "Average returns: 17.791083040161027\n",
      "Std for returns: 79.0665070351025\n",
      "(4101,)\n",
      "actions (10338, 2)\n",
      "obs (10338, 4101)\n",
      "rewards (10338,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10338,)\n",
      "actions (10338, 2)\n",
      "obs (10338, 4101)\n",
      "rewards (10338,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10338,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 254\n",
      "Average returns: 23.000299963124963\n",
      "Std for returns: 70.83762942247486\n",
      "(4101,)\n",
      "actions (11089, 2)\n",
      "obs (11089, 4101)\n",
      "rewards (11089,)\n",
      "episode_returns (100,)\n",
      "episode_starts (11089,)\n",
      "actions (11089, 2)\n",
      "obs (11089, 4101)\n",
      "rewards (11089,)\n",
      "episode_returns (100,)\n",
      "episode_starts (11089,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 175\n",
      "Average returns: 31.35651391907316\n",
      "Std for returns: 73.22932334368429\n",
      "(4101,)\n",
      "actions (9961, 2)\n",
      "obs (9961, 4101)\n",
      "rewards (9961,)\n",
      "episode_returns (100,)\n",
      "episode_starts (9961,)\n",
      "actions (9961, 2)\n",
      "obs (9961, 4101)\n",
      "rewards (9961,)\n",
      "episode_returns (100,)\n",
      "episode_starts (9961,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 161\n",
      "Average returns: 30.08224477354296\n",
      "Std for returns: 71.31017014253389\n",
      "(4101,)\n",
      "actions (10238, 2)\n",
      "obs (10238, 4101)\n",
      "rewards (10238,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10238,)\n",
      "actions (10238, 2)\n",
      "obs (10238, 4101)\n",
      "rewards (10238,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10238,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 162\n",
      "Average returns: 23.912527346456567\n",
      "Std for returns: 69.77090440227299\n",
      "(4101,)\n",
      "actions (11319, 2)\n",
      "obs (11319, 4101)\n",
      "rewards (11319,)\n",
      "episode_returns (100,)\n",
      "episode_starts (11319,)\n",
      "actions (11319, 2)\n",
      "obs (11319, 4101)\n",
      "rewards (11319,)\n",
      "episode_returns (100,)\n",
      "episode_starts (11319,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 234\n",
      "Average returns: 24.07314515380247\n",
      "Std for returns: 78.33776542429243\n",
      "(4101,)\n",
      "actions (10517, 2)\n",
      "obs (10517, 4101)\n",
      "rewards (10517,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10517,)\n",
      "actions (10517, 2)\n",
      "obs (10517, 4101)\n",
      "rewards (10517,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10517,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 107\n",
      "Average returns: 26.261614904756076\n",
      "Std for returns: 72.34680841330396\n",
      "(4101,)\n",
      "actions (10793, 2)\n",
      "obs (10793, 4101)\n",
      "rewards (10793,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10793,)\n",
      "actions (10793, 2)\n",
      "obs (10793, 4101)\n",
      "rewards (10793,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10793,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 225\n",
      "Average returns: 29.55302892066754\n",
      "Std for returns: 71.80605735137638\n",
      "(4101,)\n",
      "actions (10099, 2)\n",
      "obs (10099, 4101)\n",
      "rewards (10099,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10099,)\n",
      "actions (10099, 2)\n",
      "obs (10099, 4101)\n",
      "rewards (10099,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10099,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 231\n",
      "Average returns: 30.435901545844764\n",
      "Std for returns: 71.03771776630208\n",
      "(4101,)\n",
      "actions (10233, 2)\n",
      "obs (10233, 4101)\n",
      "rewards (10233,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10233,)\n",
      "actions (10233, 2)\n",
      "obs (10233, 4101)\n",
      "rewards (10233,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10233,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 218\n",
      "Average returns: 31.454530299734106\n",
      "Std for returns: 65.10260236793503\n",
      "(4101,)\n",
      "actions (10809, 2)\n",
      "obs (10809, 4101)\n",
      "rewards (10809,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10809,)\n",
      "actions (10809, 2)\n",
      "obs (10809, 4101)\n",
      "rewards (10809,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10809,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 220\n",
      "Average returns: 23.03999384727896\n",
      "Std for returns: 76.71244716767333\n",
      "(4101,)\n",
      "actions (10989, 2)\n",
      "obs (10989, 4101)\n",
      "rewards (10989,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10989,)\n",
      "actions (10989, 2)\n",
      "obs (10989, 4101)\n",
      "rewards (10989,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10989,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 201\n",
      "Average returns: 23.505778456756943\n",
      "Std for returns: 74.35603112999591\n",
      "(4101,)\n",
      "actions (10732, 2)\n",
      "obs (10732, 4101)\n",
      "rewards (10732,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10732,)\n",
      "actions (10732, 2)\n",
      "obs (10732, 4101)\n",
      "rewards (10732,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10732,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 151\n",
      "Average returns: 31.988288659568298\n",
      "Std for returns: 69.90722687943405\n",
      "(4101,)\n",
      "actions (10062, 2)\n",
      "obs (10062, 4101)\n",
      "rewards (10062,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10062,)\n",
      "actions (10062, 2)\n",
      "obs (10062, 4101)\n",
      "rewards (10062,)\n",
      "episode_returns (100,)\n",
      "episode_starts (10062,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 122\n",
      "Average returns: 31.668999093037602\n",
      "Std for returns: 73.42798854978041\n"
     ]
    }
   ],
   "source": [
    "env_learn = E2ENavRepEnvPretrain(silent=True, adaptive=True, collect_statistics=False)\n",
    "env_pretrain = E2ENavRepEnvPretrain(silent=True, adaptive=True, collect_statistics=False)\n",
    "model_long = PPO2(CustomPolicy, env_learn, verbose=0)\n",
    "for i in range(100):\n",
    "    alt_generate_expert_traj(env_pretrain,100,policy=FastmarchORCAPolicy(suicide_if_stuck=False), save_path = 'fmORCA_tmp', render=False)\n",
    "    dataset = ExpertDataset(expert_path='fmORCA_tmp.npz',traj_limitation=1, batch_size=64)\n",
    "    model_long.pretrain(dataset, n_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-mobile",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
