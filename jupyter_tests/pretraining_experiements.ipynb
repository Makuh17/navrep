{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "federal-onion",
   "metadata": {},
   "source": [
    "## Define ORCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "answering-triumph",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mads/miniconda3/envs/NavRepEnv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mads/miniconda3/envs/NavRepEnv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mads/miniconda3/envs/NavRepEnv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mads/miniconda3/envs/NavRepEnv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mads/miniconda3/envs/NavRepEnv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mads/miniconda3/envs/NavRepEnv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from crowd_sim.envs.policy.orca import ORCA\n",
    "from crowd_sim.envs.utils.state import JointState\n",
    "import numpy as np\n",
    "\n",
    "    \n",
    "class ORCAPolicy(object):\n",
    "    def __init__(self, suicide_if_stuck=False):\n",
    "        self.simulator = ORCA()\n",
    "        self.suicide_if_stuck = suicide_if_stuck\n",
    "\n",
    "    def reset(self):\n",
    "        self.simulator.reset()\n",
    "\n",
    "    def predict(self, obs, env):\n",
    "        self.simulator.time_step = env._get_dt()\n",
    "        other_agent_states = [\n",
    "            agent.get_observable_state() for agent in env.soadrl_sim.humans + env.soadrl_sim.other_robots]\n",
    "        action = self.simulator.predict(\n",
    "            JointState(env.soadrl_sim.robot.get_full_state(), other_agent_states),\n",
    "            env.soadrl_sim.obstacle_vertices,\n",
    "            env.soadrl_sim.robot,\n",
    "        )\n",
    "        vx = action.v * np.cos(action.r)\n",
    "        vy = action.v * np.sin(action.r)\n",
    "        return np.array([vx, vy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "accomplished-atlantic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-32.52762800052541\n",
      "0.2532474052331336\n",
      "0.28262843141272137\n",
      "-26.688682994243393\n",
      "-26.756278006305692\n",
      "0.6327754630259563\n",
      "-28.732229134588874\n",
      "-11.869005612283932\n",
      "-27.776005176029052\n",
      "0.1956912933290006\n"
     ]
    }
   ],
   "source": [
    "# Test the pre-trained model\n",
    "from navrep.envs.e2eenv import E2E1DNavRepEnv\n",
    "\n",
    "def policy_wrapper(_obs):\n",
    "    return policy.predict(_obs, env)\n",
    "\n",
    "env = E2E1DNavRepEnv(silent=True, scenario='train', adaptive=False, collect_statistics=False)\n",
    "env.soadrl_sim.human_num = 2\n",
    "obs = env.reset()\n",
    "model = policy_wrapper\n",
    "\n",
    "reward_sum = 0.0\n",
    "for _ in range(1000):\n",
    "        action = model(obs)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        reward_sum += reward\n",
    "        env.render()\n",
    "        if done:\n",
    "                print(reward_sum)\n",
    "                reward_sum = 0.0\n",
    "                obs = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-medicine",
   "metadata": {},
   "source": [
    "## Setup Env and Dummy Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worthy-understanding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ros was not found, disabled.\n"
     ]
    }
   ],
   "source": [
    "from navrep.envs.e2eenv import E2E1DNavRepEnv\n",
    "env = E2E1DNavRepEnv(silent=True, scenario='train', adaptive=False, collect_statistics=False)\n",
    "env.soadrl_sim.human_num = 2\n",
    "\n",
    "policy=ORCAPolicy(suicide_if_stuck=True)\n",
    "def policy_wrapper(_obs):\n",
    "    return policy.predict(_obs, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-honduras",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stuffed-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines import DQN\n",
    "#from stable_baselines.gail import generate_expert_traj\n",
    "from crowd_sim.envs.policy.orca import ORCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "operational-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from typing import Dict\n",
    "\n",
    "import cv2  # pytype:disable=import-error\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "from stable_baselines.common.base_class import BaseRLModel\n",
    "from stable_baselines.common.vec_env import VecEnv, VecFrameStack\n",
    "from stable_baselines.common.base_class import _UnvecWrapper\n",
    "\n",
    "\n",
    "def generate_expert_traj(model, save_path=None, env=None, n_timesteps=0,\n",
    "                         n_episodes=100, image_folder='recorded_images'):\n",
    "    \"\"\"\n",
    "    Train expert controller (if needed) and record expert trajectories.\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        only Box and Discrete spaces are supported for now.\n",
    "\n",
    "    :param model: (RL model or callable) The expert model, if it needs to be trained,\n",
    "        then you need to pass ``n_timesteps > 0``.\n",
    "    :param save_path: (str) Path without the extension where the expert dataset will be saved\n",
    "        (ex: 'expert_cartpole' -> creates 'expert_cartpole.npz').\n",
    "        If not specified, it will not save, and just return the generated expert trajectories.\n",
    "        This parameter must be specified for image-based environments.\n",
    "    :param env: (gym.Env) The environment, if not defined then it tries to use the model\n",
    "        environment.\n",
    "    :param n_timesteps: (int) Number of training timesteps\n",
    "    :param n_episodes: (int) Number of trajectories (episodes) to record\n",
    "    :param image_folder: (str) When using images, folder that will be used to record images.\n",
    "    :return: (dict) the generated expert trajectories.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve the environment using the RL model\n",
    "    if env is None and isinstance(model, BaseRLModel):\n",
    "        env = model.get_env()\n",
    "\n",
    "    assert env is not None, \"You must set the env in the model or pass it to the function.\"\n",
    "\n",
    "    is_vec_env = False\n",
    "    if isinstance(env, VecEnv) and not isinstance(env, _UnvecWrapper):\n",
    "        is_vec_env = True\n",
    "        if env.num_envs > 1:\n",
    "            warnings.warn(\"You are using multiple envs, only the data from the first one will be recorded.\")\n",
    "\n",
    "    # Sanity check\n",
    "    assert (isinstance(env.observation_space, spaces.Box) or\n",
    "            isinstance(env.observation_space, spaces.Discrete)), \"Observation space type not supported\"\n",
    "\n",
    "    assert (isinstance(env.action_space, spaces.Box) or\n",
    "            isinstance(env.action_space, spaces.Discrete)), \"Action space type not supported\"\n",
    "\n",
    "    # Check if we need to record images\n",
    "    obs_space = env.observation_space\n",
    "    record_images = len(obs_space.shape) == 3 and obs_space.shape[-1] in [1, 3, 4] \\\n",
    "                    and obs_space.dtype == np.uint8\n",
    "    if record_images and save_path is None:\n",
    "        warnings.warn(\"Observations are images but no save path was specified, so will save in numpy archive; \"\n",
    "                      \"this can lead to higher memory usage.\")\n",
    "        record_images = False\n",
    "\n",
    "    if not record_images and len(obs_space.shape) == 3 and obs_space.dtype == np.uint8:\n",
    "        warnings.warn(\"The observations looks like images (shape = {}) \"\n",
    "                      \"but the number of channel > 4, so it will be saved in the numpy archive \"\n",
    "                      \"which can lead to high memory usage\".format(obs_space.shape))\n",
    "\n",
    "    image_ext = 'jpg'\n",
    "    if record_images:\n",
    "        # We save images as jpg or png, that have only 3/4 color channels\n",
    "        if isinstance(env, VecFrameStack) and env.n_stack == 4:\n",
    "            # assert env.n_stack < 5, \"The current data recorder does no support\"\\\n",
    "            #                          \"VecFrameStack with n_stack > 4\"\n",
    "            image_ext = 'png'\n",
    "\n",
    "        folder_path = os.path.dirname(save_path)\n",
    "        image_folder = os.path.join(folder_path, image_folder)\n",
    "        os.makedirs(image_folder, exist_ok=True)\n",
    "        print(\"=\" * 10)\n",
    "        print(\"Images will be recorded to {}/\".format(image_folder))\n",
    "        print(\"Image shape: {}\".format(obs_space.shape))\n",
    "        print(\"=\" * 10)\n",
    "\n",
    "    if n_timesteps > 0 and isinstance(model, BaseRLModel):\n",
    "        model.learn(n_timesteps)\n",
    "\n",
    "    actions = []\n",
    "    observations = []\n",
    "    rewards = []\n",
    "    episode_returns = np.zeros((n_episodes,))\n",
    "    episode_starts = []\n",
    "\n",
    "    ep_idx = 0\n",
    "    obs = env.reset()\n",
    "    episode_starts.append(True)\n",
    "    reward_sum = 0.0\n",
    "    idx = 0\n",
    "    # state and mask for recurrent policies\n",
    "    state, mask = None, None\n",
    "\n",
    "    if is_vec_env:\n",
    "        mask = [True for _ in range(env.num_envs)]\n",
    "\n",
    "    while ep_idx < n_episodes:\n",
    "        obs_ = obs[0] if is_vec_env else obs\n",
    "        if record_images:\n",
    "            image_path = os.path.join(image_folder, \"{}.{}\".format(idx, image_ext))\n",
    "            # Convert from RGB to BGR\n",
    "            # which is the format OpenCV expect\n",
    "            if obs_.shape[-1] == 3:\n",
    "                obs_ = cv2.cvtColor(obs_, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(image_path, obs_)\n",
    "            observations.append(image_path)\n",
    "        else:\n",
    "            observations.append(obs_)\n",
    "\n",
    "        if isinstance(model, BaseRLModel):\n",
    "            action, state = model.predict(obs, state=state, mask=mask)\n",
    "        else:\n",
    "            action = model(obs)\n",
    "\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "\n",
    "        # Use only first env\n",
    "        if is_vec_env:\n",
    "            mask = [done[0] for _ in range(env.num_envs)]\n",
    "            action = np.array([action[0]])\n",
    "            reward = np.array([reward[0]])\n",
    "            done = np.array([done[0]])\n",
    "\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        episode_starts.append(done)\n",
    "        reward_sum += reward\n",
    "        idx += 1\n",
    "        if done:\n",
    "            if not is_vec_env:\n",
    "                obs = env.reset()\n",
    "                # Reset the state in case of a recurrent policy\n",
    "                state = None\n",
    "\n",
    "            episode_returns[ep_idx] = reward_sum\n",
    "            reward_sum = 0.0\n",
    "            ep_idx += 1\n",
    "\n",
    "    if isinstance(env.observation_space, spaces.Box) and not record_images:\n",
    "        observations = np.concatenate(observations).reshape((-1,) + env.observation_space.shape)\n",
    "    elif isinstance(env.observation_space, spaces.Discrete):\n",
    "        observations = np.array(observations).reshape((-1, 1))\n",
    "    elif record_images:\n",
    "        observations = np.array(observations)\n",
    "\n",
    "    if isinstance(env.action_space, spaces.Box):\n",
    "        actions = np.concatenate(actions).reshape((-1,) + env.action_space.shape)\n",
    "    elif isinstance(env.action_space, spaces.Discrete):\n",
    "        actions = np.array(actions).reshape((-1, 1))\n",
    "\n",
    "    rewards = np.array(rewards)\n",
    "    episode_starts = np.array(episode_starts[:-1])\n",
    "\n",
    "    assert len(observations) == len(actions)\n",
    "\n",
    "    numpy_dict = {\n",
    "        'actions': actions,\n",
    "        'obs': observations,\n",
    "        'rewards': rewards,\n",
    "        'episode_returns': episode_returns,\n",
    "        'episode_starts': episode_starts\n",
    "    }  # type: Dict[str, np.ndarray]\n",
    "\n",
    "    for key, val in numpy_dict.items():\n",
    "        print(key, val.shape)\n",
    "\n",
    "    if save_path is not None:\n",
    "        np.savez(save_path, **numpy_dict)\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    return numpy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "polished-tackle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions (113362, 2)\n",
      "obs (113362, 1085)\n",
      "rewards (113362,)\n",
      "episode_returns (1000,)\n",
      "episode_starts (113362,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'actions': array([[ 0.17292904, -0.0522805 ],\n",
       "        [ 0.24484049, -0.11186286],\n",
       "        [ 0.38693309, -0.13376042],\n",
       "        ...,\n",
       "        [-0.20220875, -0.36130958],\n",
       "        [-0.19412081, -0.34685699],\n",
       "        [-0.18635637, -0.3329825 ]]),\n",
       " 'obs': array([[ 3.20571566,  3.19619703,  3.18684173, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 3.17651463,  3.16708255,  3.15781236, ...,  0.17292904,\n",
       "         -0.0522805 ,  0.        ],\n",
       "        [ 3.13906765,  3.12974691,  3.12058592, ...,  0.24484049,\n",
       "         -0.11186286,  0.        ],\n",
       "        ...,\n",
       "        [ 4.56903791,  4.58403492,  4.59928703, ..., -0.2106337 ,\n",
       "         -0.37636444,  0.        ],\n",
       "        [ 4.56904173,  4.58403873,  4.59929085, ..., -0.20220875,\n",
       "         -0.36130958,  0.        ],\n",
       "        [ 4.56904507,  4.58404207,  4.59929419, ..., -0.19412081,\n",
       "         -0.34685699,  0.        ]]),\n",
       " 'rewards': array([ 2.50985813e-03,  4.21745056e-03,  5.87401559e-03, ...,\n",
       "        -9.91719106e-01, -9.92050342e-01, -2.50000000e+01]),\n",
       " 'episode_returns': array([ 7.70193209e+01, -2.82110989e+01, -3.33336974e+01,  2.88270221e-01,\n",
       "        -3.46681648e+01,  3.78787442e-01,  4.11732797e-01,  9.52310312e+01,\n",
       "        -2.94856603e+01,  5.31480217e-01, -8.95495355e+01, -2.94594087e+01,\n",
       "         4.90025616e-01,  6.57686142e-01, -3.44577003e+01,  4.51688508e-01,\n",
       "        -2.66584898e+01,  2.78957894e-01,  5.24904241e-01, -2.89408287e+01,\n",
       "        -1.36235870e+01,  6.68747172e-01, -2.68293624e+01,  6.22189634e-01,\n",
       "         1.79605199e-01,  6.18338189e-01, -1.70117500e+02, -2.10043226e+01,\n",
       "         2.92878212e-01,  5.39322794e-01, -1.12329677e+02,  6.67125103e-01,\n",
       "        -2.80888127e+02,  2.34322723e-01,  5.06103321e-01, -2.68122107e+01,\n",
       "         5.45586405e-01,  5.30757944e-01, -2.98528273e+01, -5.79156434e+01,\n",
       "        -2.65673149e+01,  5.53970563e-01, -3.04379125e+01, -2.79649406e+01,\n",
       "         6.58795889e-01,  6.53476206e-01, -2.78007674e+01,  2.03234955e-01,\n",
       "         6.65956681e-01,  6.68844985e-01, -5.12142344e+00,  3.51074863e-01,\n",
       "         6.62180437e-01, -2.03919232e+01, -2.68515864e+01,  6.56572902e-01,\n",
       "        -8.33152210e+00, -2.67157644e+01,  6.59295367e-01, -3.43878926e+01,\n",
       "        -1.42778844e+02, -3.77669756e+01,  3.69987178e-01, -2.95249591e+01,\n",
       "         3.08159216e-01, -2.66880008e+01, -1.47564047e+02, -2.69461496e+01,\n",
       "        -2.97211742e+01,  2.77018418e-01, -2.66939259e+01, -3.84336421e+01,\n",
       "        -5.71631484e+00, -2.78610597e+01, -5.90088196e+00,  4.32225259e-01,\n",
       "        -2.66833250e+01, -2.97527974e+01,  6.69487639e-01,  2.67113800e-01,\n",
       "         4.14478262e-01, -2.68301564e+01, -2.76239499e+01,  5.36051882e-01,\n",
       "        -1.95926063e+01, -4.35386010e+01,  4.62152049e-01, -3.06740793e+01,\n",
       "        -2.66950110e+01,  6.58772359e-01, -2.67775295e+01,  2.64470884e-01,\n",
       "        -2.68616359e+01, -3.15395768e+00,  2.58710083e-01, -6.79777536e+00,\n",
       "         5.29081647e-01,  5.55481864e-01, -6.88552332e+00, -2.57784752e+01,\n",
       "         6.47353705e-01, -2.76568009e+01, -2.95183182e+01,  2.53612179e-01,\n",
       "        -7.37722685e+00, -2.94559540e+01, -2.67173159e+01, -2.62546355e+01,\n",
       "         3.74609530e-01,  6.74400223e-01,  2.54272709e-01, -2.51488768e+00,\n",
       "        -9.39184727e+00, -2.77479739e+01, -2.68010561e+01,  6.62858606e-01,\n",
       "        -2.78834492e+01, -2.69947019e+01, -2.68071456e+01, -2.67897169e+01,\n",
       "        -6.59490555e+01,  3.81635450e-01,  5.02587394e-01, -9.36088630e+00,\n",
       "        -3.14874941e+01,  6.73189865e-01,  3.71240392e-01, -2.67454401e+01,\n",
       "         5.13794976e-01, -1.38189614e+01, -2.58275031e+01, -2.88288691e+01,\n",
       "         4.94280946e-01,  4.04829980e-01, -3.97192254e+01,  6.62690931e-01,\n",
       "         6.64595927e-01,  3.68564252e-01, -2.73954994e+01,  3.18841329e-01,\n",
       "        -2.58436685e+01, -5.19275632e+00, -3.33958197e+01, -7.85199920e+01,\n",
       "        -3.37187485e+01,  6.68801780e-01, -2.97547443e+01, -2.68138203e+01,\n",
       "        -2.89201379e+01, -1.85656376e+01,  4.17745549e-01,  2.60246453e-01,\n",
       "        -2.15102841e+02, -2.95107434e+01, -3.07807315e+01, -3.74344005e+01,\n",
       "        -2.68269759e+01,  5.12690635e-01,  2.93922583e-01, -1.18343993e-01,\n",
       "        -4.43714646e+01, -1.27226446e+01, -1.12325055e+02, -3.07778889e+01,\n",
       "         6.35506671e-01, -1.80930633e+02, -7.24136458e+00, -1.70828108e+02,\n",
       "        -1.15349816e+01, -2.78521669e+01, -2.77153944e+01, -9.17321533e+00,\n",
       "        -1.68661118e+02,  2.34365778e-01,  3.24416246e-01,  6.51449893e-01,\n",
       "        -2.14491503e+01,  3.57804704e-01,  6.65969332e-01,  2.86029165e-01,\n",
       "         6.58861625e-01,  4.87753996e-01,  6.72284496e-01,  2.21371130e-01,\n",
       "        -2.68506348e+01, -8.83555229e+01, -3.04726318e+01, -1.05001608e+01,\n",
       "         6.68394338e-01, -9.51380802e+00, -2.67164941e+01, -2.74219607e+01,\n",
       "        -2.69313842e+01,  2.97303730e-01, -3.38077436e+01, -1.42848287e+01,\n",
       "        -3.36403927e+01, -2.67907412e+01,  6.59851762e-01, -2.95551790e+01,\n",
       "        -2.85258049e+01, -2.68583924e+01, -2.85160152e+01,  6.75195473e-01,\n",
       "         6.68272816e-01, -3.05736692e+01, -9.23304978e+01, -2.69633369e+01,\n",
       "        -2.50000000e+01, -1.92416083e+01, -2.64494956e+01,  2.43570884e-01,\n",
       "         6.74019534e-01, -2.68400000e+01,  3.37445092e-01,  6.71361125e-01,\n",
       "        -7.64702415e+01, -1.15829325e+01,  6.56834131e-01, -2.83698909e+01,\n",
       "        -2.80992589e+01, -2.66986588e+01, -4.57432936e+01, -3.09835315e+01,\n",
       "         6.71324973e-01, -1.25055319e+01, -1.74223067e+01, -1.99673197e+00,\n",
       "        -2.78831607e+01,  6.64191145e-01,  6.61670300e-01,  6.69213183e-01,\n",
       "        -7.04203628e+00, -2.68240919e+01, -3.66575644e+01,  6.51826876e-01,\n",
       "         6.67796912e-01, -3.05830880e-01,  1.67413396e-01, -1.47084202e+01,\n",
       "        -4.58126852e+01,  3.81030429e-01,  4.45150367e-01,  5.28769416e-01,\n",
       "        -4.49351338e+00, -2.58479825e+01, -2.75468309e+01, -2.76874217e+01,\n",
       "        -2.88012730e+01,  6.75185813e-01, -4.05082727e+01,  6.18410716e-01,\n",
       "        -1.69399430e+02, -3.09026673e+01,  2.92438356e-01, -3.43894729e+01,\n",
       "        -2.57815260e+01, -3.54289775e+01, -1.40766351e+02, -2.69040806e+01,\n",
       "        -2.66697073e+01,  3.80735396e-01, -1.02142087e+01, -3.07327714e+01,\n",
       "        -2.85055561e+01, -1.33340289e+01,  6.65883201e-01, -3.97843433e+01,\n",
       "        -3.88622905e+01, -2.98650059e+01,  4.44903576e-01, -2.68362347e+01,\n",
       "         4.22448955e-01, -2.67161388e+01,  5.49978241e-01, -2.68215423e+01,\n",
       "        -2.67471100e+01,  2.15753674e-01, -8.70438010e+01,  6.63141730e-01,\n",
       "        -3.07336406e+01,  6.57295272e-01, -3.83416742e+01, -3.24171983e+01,\n",
       "        -1.11020354e+02, -2.96453164e+01,  4.60254011e-01, -5.02229372e+01,\n",
       "        -2.67452402e+01, -2.86015354e+01, -2.66304920e+01,  6.59932164e-01,\n",
       "        -1.68813282e+02, -1.93342969e+01,  5.08310496e-01, -2.97091277e+01,\n",
       "        -2.97698248e+01, -3.72033192e+01, -2.66463855e+01, -1.00338470e+02,\n",
       "         5.21809235e-01, -7.61387083e+00, -1.71363507e+00,  4.32575190e-01,\n",
       "        -2.66836677e+01, -2.67933432e+01, -1.10912095e+02, -2.88034643e+01,\n",
       "         5.69003156e-01,  2.94411273e-01, -2.58002163e+01, -2.67459377e+01,\n",
       "        -2.58378303e+01, -3.78908097e+01, -4.00946149e+01,  6.65079611e-01,\n",
       "        -2.67509264e+01, -1.20964533e+02, -3.05879004e+01,  2.13136393e-01,\n",
       "         6.63082179e-01, -1.34099097e+01, -2.58400000e+01, -2.76477886e+01,\n",
       "         1.73633772e-01, -2.78148399e+01, -2.88322126e+01, -4.77113752e+01,\n",
       "        -2.77263263e+01, -3.95540279e+01, -2.68258031e+01, -2.75427766e+01,\n",
       "        -3.47994694e+01, -2.79225584e+01, -2.76350689e+01, -2.89579375e+01,\n",
       "        -2.68251306e+01,  2.80280084e-01, -1.08715555e+01, -2.76350785e+01,\n",
       "        -2.68292480e+01, -2.77304920e+01, -7.11735916e+00, -2.85669283e+01,\n",
       "        -1.55601251e+02, -3.80122140e+01,  4.88786713e-01, -2.68080580e+01,\n",
       "        -2.68097815e+01, -3.04477517e+01, -7.32971583e+00, -3.38571343e+01,\n",
       "         3.80374047e-01, -2.67559851e+01, -2.26433526e+02, -2.75912650e+01,\n",
       "         3.20803504e-01,  6.61183625e-01,  6.61972170e-01, -1.03586126e+02,\n",
       "         5.39231717e-01, -3.33972825e+01, -3.32689030e+01, -3.07921711e+01,\n",
       "         4.84782388e-01, -5.73396936e+01,  6.66167774e-01, -2.68219040e+01,\n",
       "        -2.73966839e+01,  4.78928499e-01,  3.76399739e-01, -2.77081546e+01,\n",
       "        -1.18356430e+02,  6.58452323e-01, -5.23219763e+01, -2.69144756e+01,\n",
       "        -5.33467892e+01,  5.04128800e-01, -7.98006851e+01, -1.24898458e+01,\n",
       "         6.56562584e-01, -2.96899057e+01, -2.78647565e+01, -2.79439069e+01,\n",
       "         6.55080313e-01, -1.13977245e+01,  2.49765282e-01,  4.42099331e-01,\n",
       "         6.61227796e-01, -3.14557012e+01, -2.68255837e+01,  3.13458383e-01,\n",
       "        -2.72453115e+01, -3.16915598e+01,  3.98041088e-01, -1.13339653e+02,\n",
       "        -2.79605306e+01,  1.66026182e-01, -2.79405813e+01, -2.58321579e+01,\n",
       "         4.82018038e-01, -2.69649235e+01, -1.01747155e+01, -1.31332952e+02,\n",
       "        -2.67968054e+01, -4.94970764e+01, -2.76105286e+01,  2.31452425e-01,\n",
       "        -3.27336635e+01,  4.63917508e-01, -2.75624965e+01, -2.78598101e+01,\n",
       "        -9.13424748e+01, -2.46638689e+02,  5.45071788e-01, -7.91920142e+00,\n",
       "        -5.53029446e+01, -1.66492900e+01,  2.81069613e-01,  3.78315498e-01,\n",
       "         4.95302926e-01,  3.78415508e-01,  4.82591612e-01, -1.67604377e+02,\n",
       "         6.60879523e-01, -1.48763514e+00, -1.00895506e+01, -2.94495088e+01,\n",
       "        -4.84182946e+01,  6.67032727e-01, -1.20812562e+02, -1.05585635e+02,\n",
       "        -1.35677396e+01,  5.81894469e-01,  6.26339018e-01, -2.68248519e+01,\n",
       "         6.56333306e-01,  6.74711767e-01,  6.54308568e-01,  3.71721486e-01,\n",
       "        -2.69214147e+01, -2.75326624e+01, -2.77646407e+01, -2.62720011e+01,\n",
       "        -6.41101505e+01,  2.83047213e-01,  6.28844162e-01,  4.40581323e-01,\n",
       "        -3.69299725e+01, -2.67798036e+01, -2.97166888e+01, -1.30439749e+02,\n",
       "        -1.18177428e+01, -3.95325466e+01, -3.28053273e+01, -2.68153265e+01,\n",
       "        -2.67375399e+01,  6.59137547e-01, -8.09111263e+00,  6.62357454e-01,\n",
       "        -2.62731785e+01, -3.14258367e+01, -4.54775759e+01,  1.77414126e-01,\n",
       "         6.57342618e-01,  6.66149817e-01, -3.25188976e+01, -4.66764830e+01,\n",
       "        -3.75748987e+01, -2.67548175e+01, -2.67332116e+01, -3.28911090e+01,\n",
       "         5.49245010e-01, -5.03257475e+00,  6.22278531e-01,  3.92567068e-01,\n",
       "        -3.36610464e+01, -3.48208145e+01, -2.79650696e+01, -1.21898167e+01,\n",
       "         2.16777511e-01, -2.79419717e+01,  3.16042488e-01, -5.60164228e+01,\n",
       "        -2.88006148e+01, -2.59739209e+01, -2.67262666e+01,  6.72981615e-01,\n",
       "         2.27000946e-01, -5.39951327e+01, -2.67380659e+01, -8.31043738e+00,\n",
       "        -1.41964618e+02,  2.63593952e-01,  6.27991444e-01, -3.23689431e+00,\n",
       "        -2.77188323e+01, -3.37105988e+01,  3.14349261e-01, -2.58406668e+01,\n",
       "         2.44980664e-01, -1.47757381e+02, -2.67726052e+01, -3.14179972e+01,\n",
       "        -2.79741886e+01, -2.83313045e+01,  3.71752199e-01, -2.57501092e+01,\n",
       "        -3.58010203e+01, -2.67215292e+01, -1.69500552e+02, -4.45625072e+01,\n",
       "        -2.66708557e+01,  4.54970339e-01, -2.78323440e+01,  5.13789096e-01,\n",
       "         6.58158380e-01,  5.50676453e-01,  3.14934518e-01,  2.39722111e-01,\n",
       "        -2.98327801e+01, -3.03435456e+01, -3.77564314e+01,  3.69521144e-01,\n",
       "        -1.15426763e+02, -2.68188118e+01, -4.08877674e+01,  6.69278761e-01,\n",
       "        -1.57660630e+02,  6.60581855e-01, -2.57820548e+01, -2.58302653e+01,\n",
       "        -5.23323617e+01, -2.66323249e+01,  6.74528024e-01,  2.06009673e-01,\n",
       "         6.71645835e-01,  3.53076889e-01,  6.71354688e-01, -2.77775778e+01,\n",
       "        -1.28059412e+01,  1.87464256e-01, -1.47342292e+00, -2.75638338e+01,\n",
       "        -3.38217370e+01, -3.43872947e+01,  3.95832719e-01,  6.70110660e-01,\n",
       "        -8.68853430e+00,  2.09536113e-01, -2.59402009e+01,  3.26252844e-01,\n",
       "         3.95441549e-01, -2.86553867e+01, -2.59332876e+01,  2.87866386e-01,\n",
       "        -7.57304017e+00, -4.14964949e+01,  6.58750671e-01, -1.20804337e+00,\n",
       "         6.66804965e-01,  2.14724384e-01, -2.68923894e+01, -2.58196943e+01,\n",
       "        -2.85156470e+01, -2.76167703e+01,  6.65355429e-01, -3.64154419e+01,\n",
       "        -2.69909645e+01, -1.03897534e+01, -1.93730848e+01, -2.67859686e+01,\n",
       "        -2.77125497e+01, -2.68409579e+01, -2.97523560e+01, -1.46836837e+01,\n",
       "        -2.68066126e+01,  6.60095673e-01, -2.69297199e+01, -7.31055412e+00,\n",
       "        -2.75328888e+01,  6.61992984e-01,  6.40250320e-01, -8.73335573e+01,\n",
       "        -5.03317910e+01,  5.35562509e-01, -2.68173914e+01, -2.69297525e+01,\n",
       "         6.73015729e-01, -3.24069192e+01,  6.71189324e-01, -2.98556875e+01,\n",
       "        -2.67359233e+01,  2.46787574e-01, -3.04451706e+01, -2.69392940e+01,\n",
       "        -2.66469073e+01,  2.84714532e-01, -4.77390140e+01, -2.57488514e+01,\n",
       "         5.70451558e-01, -2.94782639e+01,  5.26812549e-01,  9.17625255e+01,\n",
       "         4.64622517e-01, -2.57866619e+01, -2.76363964e+01, -1.31343463e+02,\n",
       "         3.41527777e-01, -3.13249581e+01,  6.45861092e-01, -2.74276475e+01,\n",
       "        -6.27385529e+01,  6.74571425e-01, -2.78472581e+01, -9.33395012e+01,\n",
       "        -2.68116795e+01, -3.08722291e+01, -2.68163788e+01, -2.97291050e+01,\n",
       "         2.96283350e-01,  6.65704084e-01, -3.83948368e+00,  2.52454998e-01,\n",
       "         6.61315589e-01, -3.97606750e+01, -1.26819660e+02, -2.65846499e+01,\n",
       "        -3.87378406e+01, -3.87852390e+01, -6.04485774e+01,  4.57825784e-01,\n",
       "        -2.57767833e+01, -2.58469204e+01, -1.27073992e+02, -2.76151499e+01,\n",
       "         4.55662707e-01, -3.47939131e+01, -2.59919255e+01, -2.59122766e+01,\n",
       "        -2.68005524e+01,  3.39833513e-01, -3.15367247e+01, -2.58200000e+01,\n",
       "         6.60511949e-01, -1.79787605e+01,  2.37820090e-01, -2.67164114e+01,\n",
       "        -2.50000000e+01, -3.07518227e+01, -1.00934821e+01, -9.95446436e+01,\n",
       "        -2.88100934e+01, -3.97484853e+01,  3.24228180e-01,  2.30213681e-01,\n",
       "        -1.24008605e+01, -2.66590615e+01,  6.60858096e-01, -2.76827497e+01,\n",
       "         6.56836298e-01,  5.66326831e-01, -1.57413420e+02, -3.24068019e+01,\n",
       "        -2.68184949e+01, -2.78916923e+01, -2.24243378e+01, -4.48634765e+01,\n",
       "         2.42251730e-01,  3.48944242e-01,  6.57492239e-01,  2.94815732e-01,\n",
       "         6.72125098e-01, -2.35303306e+01, -3.47516192e+01, -2.68154813e+01,\n",
       "         6.68250045e-01, -3.86673788e+01,  6.65450081e-01, -2.78929882e+01,\n",
       "        -2.67715910e+01, -3.15101467e+01, -1.94557680e+00, -2.99618107e+01,\n",
       "         2.01395019e-01,  3.70932458e-01, -7.21606377e+00,  2.02999566e-01,\n",
       "        -2.57588523e+01, -7.93775994e+00, -1.37862734e+01, -3.48610963e+01,\n",
       "        -2.68110173e+01, -2.69046050e+01, -9.67819836e+00, -1.44767563e+02,\n",
       "        -2.69541038e+01, -1.61333405e+02, -9.79673132e+00,  6.62725644e-01,\n",
       "         5.73538033e-01, -2.58400000e+01, -4.35925594e+01, -2.58323131e+01,\n",
       "         6.66973068e-01, -4.56136289e+01, -2.75603224e+01, -1.32885233e+01,\n",
       "         6.63641105e-01, -2.64375176e+01,  6.70274293e-01,  4.35584988e-01,\n",
       "        -2.62687161e+02, -2.35077235e+02, -1.10824566e+02,  6.70345926e-01,\n",
       "         2.80616196e-01,  4.61109998e-01,  4.42659781e-01,  6.66380256e-01,\n",
       "        -2.85289614e+01, -8.66633019e+00, -2.67697322e+01, -2.67193173e+01,\n",
       "        -2.66694604e+01,  6.69787386e-01,  1.88659350e-01,  5.35467841e-01,\n",
       "        -3.45863627e+01,  3.41884906e-01, -9.39002211e+00,  2.00726932e-01,\n",
       "        -1.08802384e+02, -3.06791285e+01,  5.67905960e-01, -1.71419351e+01,\n",
       "        -5.30651281e+01, -3.67337865e+00, -2.77314217e+01, -9.03715017e+00,\n",
       "        -5.87986312e+01,  6.60788243e-01, -7.33067817e+00, -2.85960376e+01,\n",
       "         3.31514991e-01, -3.63855801e+01, -2.75917784e+01, -2.67012123e+01,\n",
       "         4.00810924e-01, -3.15648951e+01,  1.70863900e-01, -2.36621784e+01,\n",
       "        -2.67541045e+01, -2.57882057e+01, -2.68259275e+01, -2.76706468e+01,\n",
       "        -2.68315662e+01,  3.90979089e-01,  3.59304407e-01, -2.95394256e+01,\n",
       "         5.11631910e-01, -2.27316469e+01, -1.55573120e+02, -6.53698166e+01,\n",
       "        -3.14260406e+01, -3.28334513e+01, -2.68284274e+01, -2.57505997e+01,\n",
       "        -4.61859452e+01,  6.57208561e-01,  3.78709336e-01, -3.84651365e+01,\n",
       "        -6.75384093e+01, -9.26034709e+01, -1.49325436e+02,  4.83477991e-01,\n",
       "         6.73186397e-01, -2.68287664e+01, -9.68781917e+00, -2.85915304e+01,\n",
       "         6.64054574e-01,  2.99307936e-01, -9.33273594e+01,  5.01901964e-01,\n",
       "        -2.58791081e+01,  5.74684687e-01, -2.68207558e+01,  2.08879710e-01,\n",
       "        -3.86358356e+01,  5.71029422e-01, -2.73049594e+01, -2.57816567e+01,\n",
       "         5.07482781e-01, -3.28256671e+01, -3.02259741e+01, -1.70771363e+01,\n",
       "        -2.86053600e+01, -3.37421634e+01,  4.96108077e-01, -3.63818371e+01,\n",
       "        -2.87601674e+01,  4.14483888e-01, -9.85826312e+00,  2.38934926e-01,\n",
       "         6.38920028e-01,  2.44749091e-01,  3.18519369e-01, -7.81508676e+00,\n",
       "        -5.19127058e+01,  1.84115885e-01,  6.64961583e-01,  6.18816899e-01,\n",
       "        -2.57880665e+01, -2.66985112e+01, -2.99323447e+01,  6.64924224e-01,\n",
       "        -1.51451684e+01, -3.17826021e+01, -2.78288192e+01,  4.39244841e-01,\n",
       "        -3.84029990e+01,  2.21797828e-01, -2.78937839e+01,  6.58712761e-01,\n",
       "        -2.94581418e+01,  6.74477653e-01,  5.02466402e-01,  1.72565138e-01,\n",
       "        -7.94349725e+01,  4.87632986e-01, -1.44541980e+02, -3.24298282e+01,\n",
       "         6.64008980e-01, -2.58600000e+01, -4.59802926e+00,  4.33996507e-01,\n",
       "         6.70812546e-01,  6.73375437e-01,  5.46724854e-01,  5.38364989e-01,\n",
       "         6.59223795e-01, -5.97458566e+01, -2.86078555e+01, -1.20686907e+02,\n",
       "         2.86031236e-01, -2.68270958e+01, -7.16323508e+00, -1.56594790e+02,\n",
       "         6.60874711e-01, -2.98120707e+01, -1.53340757e+02,  2.07078451e-01,\n",
       "         2.73755711e-01, -6.23526441e+01, -1.18706759e+02,  4.15358944e-01,\n",
       "         1.95097869e-01, -8.37886160e+00, -2.88391294e+01,  2.53847975e-01,\n",
       "        -4.82060508e+01, -8.71160093e+00, -3.27968792e+01, -5.23553147e+01,\n",
       "        -2.57267798e+01,  6.16299730e-01, -4.27914614e+01, -2.69840882e+01,\n",
       "         1.96535894e-01, -7.26542127e+00,  6.66376225e-01, -1.49544169e+02,\n",
       "        -1.14934023e+01, -4.28412694e+01, -2.77896910e+01,  3.91817805e-01,\n",
       "        -1.40459769e+02, -2.85607867e+01, -2.67315258e+01, -3.77545139e+01,\n",
       "         6.73850820e-01, -2.77878925e+01, -2.68313066e+01,  3.68667000e-01,\n",
       "        -2.68214750e+01, -9.94206996e+01, -2.57889997e+01, -2.66244309e+01,\n",
       "         6.73824857e-01, -1.02452801e+02,  5.43105814e-01, -5.09028845e+01,\n",
       "         6.57067257e-01, -2.59039147e+01,  4.58680571e-01, -3.07879725e+01,\n",
       "        -1.83327211e+01, -2.58290951e+01, -1.30517370e+01,  6.03987161e-01,\n",
       "        -5.44372872e+01,  6.65618328e-01, -2.89424347e+01,  3.53685752e-01,\n",
       "        -2.58200690e+01,  6.65808449e-01, -2.69998013e+01, -1.00086917e+01,\n",
       "        -7.65641463e+00, -1.12107370e+01,  3.31772763e-01, -2.66685148e+01,\n",
       "         2.58627457e-01,  6.59184311e-01, -1.06651124e+02, -5.36007416e+01,\n",
       "         6.61652977e-01, -2.10501300e+01, -2.85084720e+01, -2.66772196e+01,\n",
       "         3.16574928e-01, -3.88357801e+01, -2.66505820e+01,  4.33143831e-01,\n",
       "        -1.98474184e+01, -2.68202552e+01, -2.83245483e+01, -2.68298871e+01,\n",
       "        -4.17635489e+01, -2.67989231e+01, -1.74870374e+01, -2.89715854e+01,\n",
       "        -2.68293055e+01,  4.56052279e-01, -2.68200000e+01, -7.43349550e+00,\n",
       "         4.47156014e-01, -9.63092133e+01, -2.68145997e+01,  1.87408167e-01,\n",
       "        -1.43544008e-01,  4.93892652e-01,  5.96881978e-01, -3.96083903e+01,\n",
       "        -2.78648741e+01,  1.81861304e-01, -4.57589829e+01,  6.56204581e-01,\n",
       "         6.65473816e-01,  4.86849957e-01, -1.74836065e+02,  3.84185775e-01,\n",
       "        -2.94773467e+01, -2.57617908e+01, -4.04595305e-02, -1.10473207e+02,\n",
       "        -1.62767291e+02, -6.26644079e+01, -1.55332771e+02, -1.26327341e+02,\n",
       "        -8.64149163e+00, -4.85753916e+01, -3.14805386e+01, -2.85374414e+01,\n",
       "        -1.94206678e+01,  4.52727744e-01,  1.74844648e-01,  6.66685585e-01,\n",
       "         3.60937962e-01, -1.73862826e+01, -9.47564790e+01, -2.78697529e+01,\n",
       "        -1.72815099e+02,  6.25340013e-01,  3.43076551e-01, -1.34378059e+01,\n",
       "         6.60847728e-01,  6.75833407e-01, -1.11245127e+02, -4.36171230e+01,\n",
       "         6.66686649e-01, -5.67958037e+00,  6.73921896e-01, -8.58524910e+00,\n",
       "        -2.68946752e+01,  6.69900393e-01, -1.60335411e+02,  5.40897715e-01,\n",
       "        -2.68040376e+01, -2.68535402e+01,  2.96555125e-01, -2.69361309e+01,\n",
       "        -3.14561454e+01,  6.60988819e-01, -4.00123314e+01,  3.87928091e-01,\n",
       "         4.22545998e-01,  4.84343415e-01,  6.31984116e-01, -2.76429934e+01]),\n",
       " 'episode_starts': array([ True, False, False, ..., False, False, False])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = DQN('MlpPolicy', 'CartPole-v1', verbose=1)\n",
    "      # Train a DQN agent for 1e5 timesteps and generate 10 trajectories\n",
    "      # data will be saved in a numpy archive named `expert_cartpole.npz`\n",
    "#generate_expert_traj(model, 'expert_cartpole', n_timesteps=int(1e5), n_episodes=10)\n",
    "\n",
    "generate_expert_traj(policy_wrapper, 'orca_1', env, n_episodes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "rocky-synthetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77.01932085 95.23103121 91.76252551]\n"
     ]
    }
   ],
   "source": [
    "tmp = np.load('orca_1.npz')\n",
    "print(tmp['episode_returns'][tmp['episode_returns']>30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.observation_space.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-enough",
   "metadata": {},
   "source": [
    "## Generate Trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-wallet",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "organic-network",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions (113362, 2)\n",
      "obs (113362, 1085)\n",
      "rewards (113362,)\n",
      "episode_returns (1000,)\n",
      "episode_starts (113362,)\n",
      "Total trajectories: 1\n",
      "Total transitions: 126\n",
      "Average returns: -19.149434741689326\n",
      "Std for returns: 38.877416667286596\n",
      "Pretraining with Behavior Cloning...\n",
      "==== Training progress 10.00% ====\n",
      "Epoch 500\n",
      "Training loss: 0.000252, Validation loss: 0.008476\n",
      "\n",
      "==== Training progress 20.00% ====\n",
      "Epoch 1000\n",
      "Training loss: 0.000036, Validation loss: 0.009115\n",
      "\n",
      "==== Training progress 30.00% ====\n",
      "Epoch 1500\n",
      "Training loss: 0.000007, Validation loss: 0.008005\n",
      "\n",
      "==== Training progress 40.00% ====\n",
      "Epoch 2000\n",
      "Training loss: 0.000004, Validation loss: 0.008114\n",
      "\n",
      "==== Training progress 50.00% ====\n",
      "Epoch 2500\n",
      "Training loss: 0.000005, Validation loss: 0.008879\n",
      "\n",
      "==== Training progress 60.00% ====\n",
      "Epoch 3000\n",
      "Training loss: 0.000022, Validation loss: 0.008303\n",
      "\n",
      "==== Training progress 70.00% ====\n",
      "Epoch 3500\n",
      "Training loss: 0.000003, Validation loss: 0.006957\n",
      "\n",
      "==== Training progress 80.00% ====\n",
      "Epoch 4000\n",
      "Training loss: 0.000001, Validation loss: 0.007323\n",
      "\n",
      "==== Training progress 90.00% ====\n",
      "Epoch 4500\n",
      "Training loss: 0.000005, Validation loss: 0.007827\n",
      "\n",
      "==== Training progress 100.00% ====\n",
      "Epoch 5000\n",
      "Training loss: 0.000013, Validation loss: 0.007387\n",
      "\n",
      "Pretraining done.\n"
     ]
    },
    {
     "ename": "ArgumentError",
     "evalue": "argument 2: <class 'TypeError'>: wrong type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7d77e5d0618b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mreward_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/NavRepEnv/lib/python3.6/site-packages/stable_baselines/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \"\"\"\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/navrep/navrep/envs/navreptrainenv.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, close, RENDER_LIDAR, lidar_scan_override, goal_override, save_to_file, show_score, robocentric)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mwin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mwin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 \u001b[0mwin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m                 \u001b[0mwin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglViewport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVP_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVP_H\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/NavRepEnv/lib/python3.6/site-packages/pyglet/window/xlib/__init__.py\u001b[0m in \u001b[0;36mdispatch_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;31m# Check for the events specific to this window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m         \u001b[0;32mwhile\u001b[0m \u001b[0mxlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXCheckWindowEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_x_display\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0x1ffffff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m             \u001b[0;31m# Key events are filtered by the xlib window event\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0;31m# handler so they get a shot at the prefiltered event.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument 2: <class 'TypeError'>: wrong type"
     ]
    }
   ],
   "source": [
    "from stable_baselines import PPO2\n",
    "from stable_baselines.gail import ExpertDataset\n",
    "from navrep.tools.custom_policy import Custom1DPolicy, ARCH, _C\n",
    "# Using only one expert trajectory\n",
    "# you can specify `traj_limitation=-1` for using the whole dataset\n",
    "dataset = ExpertDataset(expert_path='orca_1.npz',\n",
    "                        traj_limitation=1, batch_size=64)\n",
    "\n",
    "model = PPO2('MlpPolicy', env, verbose=1)\n",
    "# Pretrain the PPO2 model\n",
    "model.pretrain(dataset, n_epochs=5000)\n",
    "\n",
    "# As an option, you can train the RL agent\n",
    "# model.learn(int(1e5))\n",
    "\n",
    "# Test the pre-trained model\n",
    "env = model.get_env()\n",
    "obs = env.reset()\n",
    "\n",
    "reward_sum = 0.0\n",
    "for _ in range(1000):\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        reward_sum += reward\n",
    "        env.render()\n",
    "        if done:\n",
    "                print(reward_sum)\n",
    "                reward_sum = 0.0\n",
    "                obs = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-narrow",
   "metadata": {},
   "source": [
    "## Stable Baselines Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines import DQN\n",
    "from stable_baselines.gail import generate_expert_traj\n",
    "\n",
    "model = DQN('MlpPolicy', 'CartPole-v1', verbose=1)\n",
    "      # Train a DQN agent for 1e5 timesteps and generate 10 trajectories\n",
    "      # data will be saved in a numpy archive named `expert_cartpole.npz`\n",
    "generate_expert_traj(model, 'expert_cartpole', n_timesteps=int(1e5), n_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines import PPO2\n",
    "from stable_baselines.gail import ExpertDataset\n",
    "# Using only one expert trajectory\n",
    "# you can specify `traj_limitation=-1` for using the whole dataset\n",
    "dataset = ExpertDataset(expert_path='expert_cartpole.npz',\n",
    "                        traj_limitation=1, batch_size=128)\n",
    "\n",
    "model = PPO2('MlpPolicy', 'CartPole-v1', verbose=1)\n",
    "# Pretrain the PPO2 model\n",
    "model.pretrain(dataset, n_epochs=1000)\n",
    "\n",
    "# As an option, you can train the RL agent\n",
    "# model.learn(int(1e5))\n",
    "\n",
    "# Test the pre-trained model\n",
    "env = model.get_env()\n",
    "obs = env.reset()\n",
    "\n",
    "reward_sum = 0.0\n",
    "for _ in range(1000):\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        reward_sum += reward\n",
    "        env.render()\n",
    "        if done:\n",
    "                print(reward_sum)\n",
    "                reward_sum = 0.0\n",
    "                obs = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones(3)*np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-march",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
